{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5237 - mean_absolute_error: 0.8968\n",
      "Epoch 00001: val_loss improved from inf to 0.53064, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 82s 1ms/sample - loss: 0.5238 - mean_absolute_error: 0.8968 - val_loss: 0.5306 - val_mean_absolute_error: 0.9016\n",
      "Epoch 2/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5125 - mean_absolute_error: 0.8834\n",
      "Epoch 00002: val_loss improved from 0.53064 to 0.52704, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.5125 - mean_absolute_error: 0.8834 - val_loss: 0.5270 - val_mean_absolute_error: 0.8971\n",
      "Epoch 3/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5060 - mean_absolute_error: 0.8758\n",
      "Epoch 00003: val_loss improved from 0.52704 to 0.52336, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.5060 - mean_absolute_error: 0.8758 - val_loss: 0.5234 - val_mean_absolute_error: 0.8937\n",
      "Epoch 4/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4998 - mean_absolute_error: 0.8684\n",
      "Epoch 00004: val_loss improved from 0.52336 to 0.52073, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.4998 - mean_absolute_error: 0.8684 - val_loss: 0.5207 - val_mean_absolute_error: 0.8898\n",
      "Epoch 5/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4909 - mean_absolute_error: 0.8580\n",
      "Epoch 00005: val_loss improved from 0.52073 to 0.51423, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.4909 - mean_absolute_error: 0.8580 - val_loss: 0.5142 - val_mean_absolute_error: 0.8827\n",
      "Epoch 6/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4790 - mean_absolute_error: 0.8438\n",
      "Epoch 00006: val_loss improved from 0.51423 to 0.50944, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.4790 - mean_absolute_error: 0.8438 - val_loss: 0.5094 - val_mean_absolute_error: 0.8769\n",
      "Epoch 7/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4634 - mean_absolute_error: 0.8248\n",
      "Epoch 00007: val_loss improved from 0.50944 to 0.50506, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.4634 - mean_absolute_error: 0.8248 - val_loss: 0.5051 - val_mean_absolute_error: 0.8716\n",
      "Epoch 8/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4432 - mean_absolute_error: 0.8001\n",
      "Epoch 00008: val_loss improved from 0.50506 to 0.50117, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.4432 - mean_absolute_error: 0.8001 - val_loss: 0.5012 - val_mean_absolute_error: 0.8656\n",
      "Epoch 9/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4192 - mean_absolute_error: 0.7716\n",
      "Epoch 00009: val_loss improved from 0.50117 to 0.50009, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.4193 - mean_absolute_error: 0.7716 - val_loss: 0.5001 - val_mean_absolute_error: 0.8658\n",
      "Epoch 10/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3961 - mean_absolute_error: 0.7435\n",
      "Epoch 00010: val_loss improved from 0.50009 to 0.49753, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.3961 - mean_absolute_error: 0.7435 - val_loss: 0.4975 - val_mean_absolute_error: 0.8624\n",
      "Epoch 11/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3720 - mean_absolute_error: 0.7147\n",
      "Epoch 00011: val_loss improved from 0.49753 to 0.49327, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.3720 - mean_absolute_error: 0.7147 - val_loss: 0.4933 - val_mean_absolute_error: 0.8576\n",
      "Epoch 12/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3517 - mean_absolute_error: 0.6901\n",
      "Epoch 00012: val_loss improved from 0.49327 to 0.49132, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.3517 - mean_absolute_error: 0.6901 - val_loss: 0.4913 - val_mean_absolute_error: 0.8544\n",
      "Epoch 13/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3335 - mean_absolute_error: 0.6677\n",
      "Epoch 00013: val_loss improved from 0.49132 to 0.48810, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.3335 - mean_absolute_error: 0.6677 - val_loss: 0.4881 - val_mean_absolute_error: 0.8512\n",
      "Epoch 14/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3178 - mean_absolute_error: 0.6482\n",
      "Epoch 00014: val_loss did not improve from 0.48810\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.3178 - mean_absolute_error: 0.6483 - val_loss: 0.4917 - val_mean_absolute_error: 0.8556\n",
      "Epoch 15/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3058 - mean_absolute_error: 0.6334\n",
      "Epoch 00015: val_loss improved from 0.48810 to 0.48550, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.3058 - mean_absolute_error: 0.6334 - val_loss: 0.4855 - val_mean_absolute_error: 0.8478\n",
      "Epoch 16/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2954 - mean_absolute_error: 0.6202\n",
      "Epoch 00016: val_loss did not improve from 0.48550\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2954 - mean_absolute_error: 0.6202 - val_loss: 0.4882 - val_mean_absolute_error: 0.8509\n",
      "Epoch 17/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2874 - mean_absolute_error: 0.6103\n",
      "Epoch 00017: val_loss improved from 0.48550 to 0.48402, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.2874 - mean_absolute_error: 0.6103 - val_loss: 0.4840 - val_mean_absolute_error: 0.8461\n",
      "Epoch 18/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2803 - mean_absolute_error: 0.6012\n",
      "Epoch 00018: val_loss improved from 0.48402 to 0.48135, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.2803 - mean_absolute_error: 0.6011 - val_loss: 0.4814 - val_mean_absolute_error: 0.8424\n",
      "Epoch 19/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2751 - mean_absolute_error: 0.5945\n",
      "Epoch 00019: val_loss improved from 0.48135 to 0.48106, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2751 - mean_absolute_error: 0.5946 - val_loss: 0.4811 - val_mean_absolute_error: 0.8421\n",
      "Epoch 20/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2695 - mean_absolute_error: 0.5872\n",
      "Epoch 00020: val_loss did not improve from 0.48106\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2696 - mean_absolute_error: 0.5872 - val_loss: 0.4826 - val_mean_absolute_error: 0.8445\n",
      "Epoch 21/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2657 - mean_absolute_error: 0.5822\n",
      "Epoch 00021: val_loss improved from 0.48106 to 0.48048, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2657 - mean_absolute_error: 0.5822 - val_loss: 0.4805 - val_mean_absolute_error: 0.8410\n",
      "Epoch 22/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2613 - mean_absolute_error: 0.5759\n",
      "Epoch 00022: val_loss improved from 0.48048 to 0.47856, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.2612 - mean_absolute_error: 0.5759 - val_loss: 0.4786 - val_mean_absolute_error: 0.8390\n",
      "Epoch 23/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2582 - mean_absolute_error: 0.5720\n",
      "Epoch 00023: val_loss did not improve from 0.47856\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2582 - mean_absolute_error: 0.5720 - val_loss: 0.4817 - val_mean_absolute_error: 0.8428\n",
      "Epoch 24/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2550 - mean_absolute_error: 0.5676\n",
      "Epoch 00024: val_loss did not improve from 0.47856\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2550 - mean_absolute_error: 0.5676 - val_loss: 0.4806 - val_mean_absolute_error: 0.8412\n",
      "Epoch 25/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2523 - mean_absolute_error: 0.5641\n",
      "Epoch 00025: val_loss did not improve from 0.47856\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2523 - mean_absolute_error: 0.5641 - val_loss: 0.4787 - val_mean_absolute_error: 0.8386\n",
      "Epoch 26/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2511 - mean_absolute_error: 0.5625\n",
      "Epoch 00026: val_loss did not improve from 0.47856\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2511 - mean_absolute_error: 0.5625 - val_loss: 0.4793 - val_mean_absolute_error: 0.8396\n",
      "Epoch 27/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2476 - mean_absolute_error: 0.5575\n",
      "Epoch 00027: val_loss improved from 0.47856 to 0.47800, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.2476 - mean_absolute_error: 0.5575 - val_loss: 0.4780 - val_mean_absolute_error: 0.8376\n",
      "Epoch 28/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2461 - mean_absolute_error: 0.5556\n",
      "Epoch 00028: val_loss improved from 0.47800 to 0.47627, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 75s 1ms/sample - loss: 0.2461 - mean_absolute_error: 0.5556 - val_loss: 0.4763 - val_mean_absolute_error: 0.8358\n",
      "Epoch 29/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2441 - mean_absolute_error: 0.5528\n",
      "Epoch 00029: val_loss improved from 0.47627 to 0.47264, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 74s 1ms/sample - loss: 0.2441 - mean_absolute_error: 0.5527 - val_loss: 0.4726 - val_mean_absolute_error: 0.8311\n",
      "Epoch 30/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2424 - mean_absolute_error: 0.5505\n",
      "Epoch 00030: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2424 - mean_absolute_error: 0.5505 - val_loss: 0.4746 - val_mean_absolute_error: 0.8335\n",
      "Epoch 31/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2425 - mean_absolute_error: 0.5505\n",
      "Epoch 00031: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2425 - mean_absolute_error: 0.5505 - val_loss: 0.4743 - val_mean_absolute_error: 0.8334\n",
      "Epoch 32/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2407 - mean_absolute_error: 0.5481\n",
      "Epoch 00032: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2407 - mean_absolute_error: 0.5481 - val_loss: 0.4742 - val_mean_absolute_error: 0.8329\n",
      "Epoch 33/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2398 - mean_absolute_error: 0.5465\n",
      "Epoch 00033: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2398 - mean_absolute_error: 0.5465 - val_loss: 0.4735 - val_mean_absolute_error: 0.8318\n",
      "Epoch 34/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2383 - mean_absolute_error: 0.5445\n",
      "Epoch 00034: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2383 - mean_absolute_error: 0.5445 - val_loss: 0.4730 - val_mean_absolute_error: 0.8312\n",
      "Epoch 35/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2369 - mean_absolute_error: 0.5425\n",
      "Epoch 00035: val_loss did not improve from 0.47264\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2369 - mean_absolute_error: 0.5425 - val_loss: 0.4735 - val_mean_absolute_error: 0.8317\n",
      "Epoch 36/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2367 - mean_absolute_error: 0.5422\n",
      "Epoch 00036: val_loss improved from 0.47264 to 0.47158, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2367 - mean_absolute_error: 0.5422 - val_loss: 0.4716 - val_mean_absolute_error: 0.8294\n",
      "Epoch 37/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2357 - mean_absolute_error: 0.5408\n",
      "Epoch 00037: val_loss improved from 0.47158 to 0.47065, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2357 - mean_absolute_error: 0.5408 - val_loss: 0.4707 - val_mean_absolute_error: 0.8286\n",
      "Epoch 38/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2344 - mean_absolute_error: 0.5389\n",
      "Epoch 00038: val_loss did not improve from 0.47065\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2344 - mean_absolute_error: 0.5389 - val_loss: 0.4724 - val_mean_absolute_error: 0.8298\n",
      "Epoch 39/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2334 - mean_absolute_error: 0.5376\n",
      "Epoch 00039: val_loss did not improve from 0.47065\n",
      "67485/67485 [==============================] - 71s 1ms/sample - loss: 0.2334 - mean_absolute_error: 0.5376 - val_loss: 0.4716 - val_mean_absolute_error: 0.8294\n",
      "Epoch 40/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2329 - mean_absolute_error: 0.5368\n",
      "Epoch 00040: val_loss improved from 0.47065 to 0.47045, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 71s 1ms/sample - loss: 0.2330 - mean_absolute_error: 0.5369 - val_loss: 0.4704 - val_mean_absolute_error: 0.8281\n",
      "Epoch 41/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2320 - mean_absolute_error: 0.5355\n",
      "Epoch 00041: val_loss did not improve from 0.47045\n",
      "67485/67485 [==============================] - 71s 1ms/sample - loss: 0.2320 - mean_absolute_error: 0.5355 - val_loss: 0.4719 - val_mean_absolute_error: 0.8299\n",
      "Epoch 42/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2317 - mean_absolute_error: 0.5352\n",
      "Epoch 00042: val_loss did not improve from 0.47045\n",
      "67485/67485 [==============================] - 71s 1ms/sample - loss: 0.2317 - mean_absolute_error: 0.5353 - val_loss: 0.4736 - val_mean_absolute_error: 0.8316\n",
      "Epoch 43/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2311 - mean_absolute_error: 0.5343\n",
      "Epoch 00043: val_loss did not improve from 0.47045\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2311 - mean_absolute_error: 0.5343 - val_loss: 0.4710 - val_mean_absolute_error: 0.8286\n",
      "Epoch 44/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2302 - mean_absolute_error: 0.5329\n",
      "Epoch 00044: val_loss did not improve from 0.47045\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2303 - mean_absolute_error: 0.5329 - val_loss: 0.4706 - val_mean_absolute_error: 0.8277\n",
      "Epoch 45/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2299 - mean_absolute_error: 0.5323\n",
      "Epoch 00045: val_loss improved from 0.47045 to 0.46951, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2299 - mean_absolute_error: 0.5323 - val_loss: 0.4695 - val_mean_absolute_error: 0.8265\n",
      "Epoch 46/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2290 - mean_absolute_error: 0.5310\n",
      "Epoch 00046: val_loss did not improve from 0.46951\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2289 - mean_absolute_error: 0.5310 - val_loss: 0.4715 - val_mean_absolute_error: 0.8289\n",
      "Epoch 47/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2289 - mean_absolute_error: 0.5310\n",
      "Epoch 00047: val_loss did not improve from 0.46951\n",
      "67485/67485 [==============================] - 73s 1ms/sample - loss: 0.2289 - mean_absolute_error: 0.5310 - val_loss: 0.4722 - val_mean_absolute_error: 0.8297\n",
      "Epoch 48/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2284 - mean_absolute_error: 0.5302\n",
      "Epoch 00048: val_loss did not improve from 0.46951\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2284 - mean_absolute_error: 0.5303 - val_loss: 0.4696 - val_mean_absolute_error: 0.8268\n",
      "Epoch 49/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2279 - mean_absolute_error: 0.5295\n",
      "Epoch 00049: val_loss did not improve from 0.46951\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2278 - mean_absolute_error: 0.5294 - val_loss: 0.4698 - val_mean_absolute_error: 0.8267\n",
      "Epoch 50/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2274 - mean_absolute_error: 0.5284\n",
      "Epoch 00050: val_loss improved from 0.46951 to 0.46904, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1500-b.h5\n",
      "67485/67485 [==============================] - 72s 1ms/sample - loss: 0.2273 - mean_absolute_error: 0.5284 - val_loss: 0.4690 - val_mean_absolute_error: 0.8261\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 1500\n",
    "# 40% dropout\n",
    "DROPOUT = 0.25\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "LAYER_ACTIVATION = \"linear\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
