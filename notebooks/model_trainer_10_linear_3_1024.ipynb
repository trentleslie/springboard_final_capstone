{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5246 - mean_absolute_error: 0.8975\n",
      "Epoch 00001: val_loss improved from inf to 0.52918, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 43s 635us/sample - loss: 0.5245 - mean_absolute_error: 0.8974 - val_loss: 0.5292 - val_mean_absolute_error: 0.9005\n",
      "Epoch 2/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5146 - mean_absolute_error: 0.8855\n",
      "Epoch 00002: val_loss improved from 0.52918 to 0.51939, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 520us/sample - loss: 0.5146 - mean_absolute_error: 0.8854 - val_loss: 0.5194 - val_mean_absolute_error: 0.8887\n",
      "Epoch 3/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5088 - mean_absolute_error: 0.8786\n",
      "Epoch 00003: val_loss improved from 0.51939 to 0.51488, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 523us/sample - loss: 0.5089 - mean_absolute_error: 0.8786 - val_loss: 0.5149 - val_mean_absolute_error: 0.8838\n",
      "Epoch 4/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5018 - mean_absolute_error: 0.8701\n",
      "Epoch 00004: val_loss improved from 0.51488 to 0.51231, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 516us/sample - loss: 0.5017 - mean_absolute_error: 0.8700 - val_loss: 0.5123 - val_mean_absolute_error: 0.8806\n",
      "Epoch 5/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4937 - mean_absolute_error: 0.8608\n",
      "Epoch 00005: val_loss improved from 0.51231 to 0.51151, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 512us/sample - loss: 0.4937 - mean_absolute_error: 0.8609 - val_loss: 0.5115 - val_mean_absolute_error: 0.8800\n",
      "Epoch 6/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4831 - mean_absolute_error: 0.8483\n",
      "Epoch 00006: val_loss improved from 0.51151 to 0.50398, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 502us/sample - loss: 0.4831 - mean_absolute_error: 0.8483 - val_loss: 0.5040 - val_mean_absolute_error: 0.8708\n",
      "Epoch 7/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4698 - mean_absolute_error: 0.8323\n",
      "Epoch 00007: val_loss improved from 0.50398 to 0.50059, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 510us/sample - loss: 0.4698 - mean_absolute_error: 0.8322 - val_loss: 0.5006 - val_mean_absolute_error: 0.8670\n",
      "Epoch 8/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4533 - mean_absolute_error: 0.8123\n",
      "Epoch 00008: val_loss improved from 0.50059 to 0.49820, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 522us/sample - loss: 0.4534 - mean_absolute_error: 0.8124 - val_loss: 0.4982 - val_mean_absolute_error: 0.8639\n",
      "Epoch 9/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4354 - mean_absolute_error: 0.7912\n",
      "Epoch 00009: val_loss improved from 0.49820 to 0.49132, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 510us/sample - loss: 0.4354 - mean_absolute_error: 0.7912 - val_loss: 0.4913 - val_mean_absolute_error: 0.8560\n",
      "Epoch 10/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4158 - mean_absolute_error: 0.7675\n",
      "Epoch 00010: val_loss improved from 0.49132 to 0.48927, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 505us/sample - loss: 0.4157 - mean_absolute_error: 0.7674 - val_loss: 0.4893 - val_mean_absolute_error: 0.8534\n",
      "Epoch 11/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3958 - mean_absolute_error: 0.7431\n",
      "Epoch 00011: val_loss improved from 0.48927 to 0.48536, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 506us/sample - loss: 0.3959 - mean_absolute_error: 0.7432 - val_loss: 0.4854 - val_mean_absolute_error: 0.8485\n",
      "Epoch 12/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3786 - mean_absolute_error: 0.7226\n",
      "Epoch 00012: val_loss improved from 0.48536 to 0.48397, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 508us/sample - loss: 0.3786 - mean_absolute_error: 0.7226 - val_loss: 0.4840 - val_mean_absolute_error: 0.8470\n",
      "Epoch 13/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3626 - mean_absolute_error: 0.7031\n",
      "Epoch 00013: val_loss did not improve from 0.48397\n",
      "67485/67485 [==============================] - 34s 502us/sample - loss: 0.3625 - mean_absolute_error: 0.7030 - val_loss: 0.4844 - val_mean_absolute_error: 0.8471\n",
      "Epoch 14/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3500 - mean_absolute_error: 0.6876\n",
      "Epoch 00014: val_loss improved from 0.48397 to 0.47991, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 507us/sample - loss: 0.3499 - mean_absolute_error: 0.6875 - val_loss: 0.4799 - val_mean_absolute_error: 0.8415\n",
      "Epoch 15/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3375 - mean_absolute_error: 0.6725\n",
      "Epoch 00015: val_loss did not improve from 0.47991\n",
      "67485/67485 [==============================] - 34s 507us/sample - loss: 0.3376 - mean_absolute_error: 0.6725 - val_loss: 0.4860 - val_mean_absolute_error: 0.8492\n",
      "Epoch 16/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3263 - mean_absolute_error: 0.6587\n",
      "Epoch 00016: val_loss improved from 0.47991 to 0.47982, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 518us/sample - loss: 0.3264 - mean_absolute_error: 0.6587 - val_loss: 0.4798 - val_mean_absolute_error: 0.8419\n",
      "Epoch 17/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3164 - mean_absolute_error: 0.6467\n",
      "Epoch 00017: val_loss improved from 0.47982 to 0.47959, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 526us/sample - loss: 0.3164 - mean_absolute_error: 0.6466 - val_loss: 0.4796 - val_mean_absolute_error: 0.8414\n",
      "Epoch 18/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3096 - mean_absolute_error: 0.6380\n",
      "Epoch 00018: val_loss improved from 0.47959 to 0.47821, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 36s 527us/sample - loss: 0.3096 - mean_absolute_error: 0.6380 - val_loss: 0.4782 - val_mean_absolute_error: 0.8401\n",
      "Epoch 19/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3025 - mean_absolute_error: 0.6287\n",
      "Epoch 00019: val_loss improved from 0.47821 to 0.47481, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 514us/sample - loss: 0.3024 - mean_absolute_error: 0.6286 - val_loss: 0.4748 - val_mean_absolute_error: 0.8356\n",
      "Epoch 20/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2964 - mean_absolute_error: 0.6208\n",
      "Epoch 00020: val_loss did not improve from 0.47481\n",
      "67485/67485 [==============================] - 35s 517us/sample - loss: 0.2964 - mean_absolute_error: 0.6208 - val_loss: 0.4753 - val_mean_absolute_error: 0.8360\n",
      "Epoch 21/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2904 - mean_absolute_error: 0.6134\n",
      "Epoch 00021: val_loss did not improve from 0.47481\n",
      "67485/67485 [==============================] - 35s 521us/sample - loss: 0.2904 - mean_absolute_error: 0.6134 - val_loss: 0.4778 - val_mean_absolute_error: 0.8385\n",
      "Epoch 22/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2859 - mean_absolute_error: 0.6082\n",
      "Epoch 00022: val_loss improved from 0.47481 to 0.47392, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 523us/sample - loss: 0.2858 - mean_absolute_error: 0.6081 - val_loss: 0.4739 - val_mean_absolute_error: 0.8343\n",
      "Epoch 23/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2824 - mean_absolute_error: 0.6034\n",
      "Epoch 00023: val_loss did not improve from 0.47392\n",
      "67485/67485 [==============================] - 36s 528us/sample - loss: 0.2824 - mean_absolute_error: 0.6033 - val_loss: 0.4739 - val_mean_absolute_error: 0.8338\n",
      "Epoch 24/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2801 - mean_absolute_error: 0.6006\n",
      "Epoch 00024: val_loss did not improve from 0.47392\n",
      "67485/67485 [==============================] - 34s 507us/sample - loss: 0.2801 - mean_absolute_error: 0.6006 - val_loss: 0.4755 - val_mean_absolute_error: 0.8358\n",
      "Epoch 25/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2750 - mean_absolute_error: 0.5934\n",
      "Epoch 00025: val_loss improved from 0.47392 to 0.47349, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 34s 511us/sample - loss: 0.2752 - mean_absolute_error: 0.5937 - val_loss: 0.4735 - val_mean_absolute_error: 0.8329\n",
      "Epoch 26/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2716 - mean_absolute_error: 0.5896\n",
      "Epoch 00026: val_loss improved from 0.47349 to 0.47163, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 36s 537us/sample - loss: 0.2716 - mean_absolute_error: 0.5896 - val_loss: 0.4716 - val_mean_absolute_error: 0.8308\n",
      "Epoch 27/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2694 - mean_absolute_error: 0.5863\n",
      "Epoch 00027: val_loss did not improve from 0.47163\n",
      "67485/67485 [==============================] - 36s 531us/sample - loss: 0.2694 - mean_absolute_error: 0.5863 - val_loss: 0.4718 - val_mean_absolute_error: 0.8312\n",
      "Epoch 28/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2673 - mean_absolute_error: 0.5833\n",
      "Epoch 00028: val_loss improved from 0.47163 to 0.47156, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 525us/sample - loss: 0.2673 - mean_absolute_error: 0.5833 - val_loss: 0.4716 - val_mean_absolute_error: 0.8306\n",
      "Epoch 29/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2659 - mean_absolute_error: 0.5818\n",
      "Epoch 00029: val_loss did not improve from 0.47156\n",
      "67485/67485 [==============================] - 34s 509us/sample - loss: 0.2660 - mean_absolute_error: 0.5819 - val_loss: 0.4721 - val_mean_absolute_error: 0.8312\n",
      "Epoch 30/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2628 - mean_absolute_error: 0.5777\n",
      "Epoch 00030: val_loss did not improve from 0.47156\n",
      "67485/67485 [==============================] - 35s 511us/sample - loss: 0.2628 - mean_absolute_error: 0.5777 - val_loss: 0.4732 - val_mean_absolute_error: 0.8330\n",
      "Epoch 31/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2615 - mean_absolute_error: 0.5757\n",
      "Epoch 00031: val_loss improved from 0.47156 to 0.46748, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 516us/sample - loss: 0.2616 - mean_absolute_error: 0.5758 - val_loss: 0.4675 - val_mean_absolute_error: 0.8255\n",
      "Epoch 32/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2594 - mean_absolute_error: 0.5730\n",
      "Epoch 00032: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 523us/sample - loss: 0.2594 - mean_absolute_error: 0.5730 - val_loss: 0.4705 - val_mean_absolute_error: 0.8292\n",
      "Epoch 33/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2583 - mean_absolute_error: 0.5717\n",
      "Epoch 00033: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 520us/sample - loss: 0.2583 - mean_absolute_error: 0.5717 - val_loss: 0.4720 - val_mean_absolute_error: 0.8311\n",
      "Epoch 34/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2561 - mean_absolute_error: 0.5686\n",
      "Epoch 00034: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 523us/sample - loss: 0.2560 - mean_absolute_error: 0.5686 - val_loss: 0.4683 - val_mean_absolute_error: 0.8266\n",
      "Epoch 35/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2548 - mean_absolute_error: 0.5667\n",
      "Epoch 00035: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 514us/sample - loss: 0.2548 - mean_absolute_error: 0.5668 - val_loss: 0.4688 - val_mean_absolute_error: 0.8277\n",
      "Epoch 36/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2541 - mean_absolute_error: 0.5662\n",
      "Epoch 00036: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 34s 509us/sample - loss: 0.2540 - mean_absolute_error: 0.5662 - val_loss: 0.4683 - val_mean_absolute_error: 0.8264\n",
      "Epoch 37/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2527 - mean_absolute_error: 0.5639\n",
      "Epoch 00037: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 515us/sample - loss: 0.2527 - mean_absolute_error: 0.5638 - val_loss: 0.4692 - val_mean_absolute_error: 0.8277\n",
      "Epoch 38/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2531 - mean_absolute_error: 0.5645\n",
      "Epoch 00038: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 512us/sample - loss: 0.2530 - mean_absolute_error: 0.5644 - val_loss: 0.4686 - val_mean_absolute_error: 0.8268\n",
      "Epoch 39/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2507 - mean_absolute_error: 0.5614\n",
      "Epoch 00039: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 514us/sample - loss: 0.2508 - mean_absolute_error: 0.5614 - val_loss: 0.4705 - val_mean_absolute_error: 0.8291\n",
      "Epoch 40/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2503 - mean_absolute_error: 0.5607\n",
      "Epoch 00040: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 516us/sample - loss: 0.2503 - mean_absolute_error: 0.5607 - val_loss: 0.4677 - val_mean_absolute_error: 0.8255\n",
      "Epoch 41/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2484 - mean_absolute_error: 0.5581\n",
      "Epoch 00041: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 521us/sample - loss: 0.2484 - mean_absolute_error: 0.5580 - val_loss: 0.4688 - val_mean_absolute_error: 0.8269\n",
      "Epoch 42/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2473 - mean_absolute_error: 0.5568\n",
      "Epoch 00042: val_loss did not improve from 0.46748\n",
      "67485/67485 [==============================] - 35s 517us/sample - loss: 0.2472 - mean_absolute_error: 0.5567 - val_loss: 0.4681 - val_mean_absolute_error: 0.8263\n",
      "Epoch 43/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2474 - mean_absolute_error: 0.5569\n",
      "Epoch 00043: val_loss improved from 0.46748 to 0.46703, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 36s 526us/sample - loss: 0.2474 - mean_absolute_error: 0.5570 - val_loss: 0.4670 - val_mean_absolute_error: 0.8243\n",
      "Epoch 44/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2466 - mean_absolute_error: 0.5558\n",
      "Epoch 00044: val_loss did not improve from 0.46703\n",
      "67485/67485 [==============================] - 34s 508us/sample - loss: 0.2466 - mean_absolute_error: 0.5558 - val_loss: 0.4672 - val_mean_absolute_error: 0.8248\n",
      "Epoch 45/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2455 - mean_absolute_error: 0.5545\n",
      "Epoch 00045: val_loss did not improve from 0.46703\n",
      "67485/67485 [==============================] - 36s 526us/sample - loss: 0.2455 - mean_absolute_error: 0.5545 - val_loss: 0.4695 - val_mean_absolute_error: 0.8278\n",
      "Epoch 46/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2447 - mean_absolute_error: 0.5537\n",
      "Epoch 00046: val_loss improved from 0.46703 to 0.46353, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-3-units-1024-b.h5\n",
      "67485/67485 [==============================] - 35s 517us/sample - loss: 0.2447 - mean_absolute_error: 0.5537 - val_loss: 0.4635 - val_mean_absolute_error: 0.8200\n",
      "Epoch 47/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2444 - mean_absolute_error: 0.5529\n",
      "Epoch 00047: val_loss did not improve from 0.46353\n",
      "67485/67485 [==============================] - 35s 512us/sample - loss: 0.2445 - mean_absolute_error: 0.5530 - val_loss: 0.4672 - val_mean_absolute_error: 0.8241\n",
      "Epoch 48/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2433 - mean_absolute_error: 0.5514\n",
      "Epoch 00048: val_loss did not improve from 0.46353\n",
      "67485/67485 [==============================] - 34s 510us/sample - loss: 0.2433 - mean_absolute_error: 0.5514 - val_loss: 0.4664 - val_mean_absolute_error: 0.8231\n",
      "Epoch 49/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2436 - mean_absolute_error: 0.5516\n",
      "Epoch 00049: val_loss did not improve from 0.46353\n",
      "67485/67485 [==============================] - 34s 510us/sample - loss: 0.2435 - mean_absolute_error: 0.5516 - val_loss: 0.4674 - val_mean_absolute_error: 0.8247\n",
      "Epoch 50/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2427 - mean_absolute_error: 0.5506\n",
      "Epoch 00050: val_loss did not improve from 0.46353\n",
      "67485/67485 [==============================] - 35s 520us/sample - loss: 0.2427 - mean_absolute_error: 0.5506 - val_loss: 0.4682 - val_mean_absolute_error: 0.8261\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 1024\n",
    "# 40% dropout\n",
    "DROPOUT = 0.3\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "LAYER_ACTIVATION = \"linear\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
