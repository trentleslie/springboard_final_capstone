{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY saved\n",
      "QQQ saved\n",
      "XLF saved\n",
      "EEM saved\n",
      "XLE saved\n",
      "SLV saved\n",
      "FXI saved\n",
      "GDX saved\n",
      "EFA saved\n",
      "TLT saved\n",
      "LQD saved\n",
      "XLU saved\n",
      "XLV saved\n",
      "XLI saved\n",
      "IEMG saved\n",
      "VWO saved\n",
      "XLK saved\n",
      "IEF saved\n",
      "XLB saved\n",
      "JETS saved\n",
      "BND saved\n"
     ]
    }
   ],
   "source": [
    "# symbols and technical indicators [code, interval, name]\n",
    "# https://www.alphavantage.co/documentation/#technical-indicators\n",
    "#\n",
    "# got rid of JNK (weirdly high open z-score mean), HYG (weirdly low low z-score mean), and EWZ/IEF (infinite end values)\n",
    "\n",
    "symbol_list = ['SPY','QQQ','XLF','EEM','XLE','SLV','FXI','GDX','EFA','TLT','LQD','XLU','XLV','XLI','IEMG','VWO','XLK','IEF','XLB','JETS','BND']\n",
    "tech_list = [['SMA',50,'Technical Analysis: SMA'],\n",
    "             ['EMA',21,'Technical Analysis: EMA'],\n",
    "             ['RSI',14,'Technical Analysis: RSI']]\n",
    "\n",
    "for symbol in symbol_list:\n",
    "\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&outputsize=full&apikey=PDS8Y8E8KULJVDET\"\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df_price = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "    time.sleep(15)\n",
    "\n",
    "    for tech in tech_list:\n",
    "        url = f\"https://www.alphavantage.co/query?function={tech[0]}&symbol={symbol}&interval=daily&time_period={tech[1]}&series_type=close&apikey=PDS8Y8E8KULJVDET\"\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        df_tech = pd.DataFrame(data[tech[2]]).T\n",
    "        df_price = df_price.merge(df_tech, how='inner', left_index=True, right_index=True)\n",
    "        time.sleep(15)\n",
    "    \n",
    "    df_price.to_csv(f\"../data/predict/{symbol}_daily.csv\")\n",
    "    print(f\"This will take about {len(symbol_list)*15/60} minutes to run.\")\n",
    "    #print(f\"{symbol} saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [20,320]\n",
    "\n",
    "def zscore(x, window):\n",
    "    r = x.rolling(window=window)\n",
    "    m = r.mean().shift(1)\n",
    "    s = r.std(ddof=0).shift(1)\n",
    "    z = (x-m)/s\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir('../data/predict/') if isfile(join('../data/predict/', f))]\n",
    "onlyfiles = list(filter(lambda thisfilename: '_daily.csv' in thisfilename, onlyfiles))\n",
    "\n",
    "ticker_list = []\n",
    "ticker_stats_mean = pd.DataFrame()\n",
    "ticker_stats_std = pd.DataFrame()\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    for filename in onlyfiles:\n",
    "        ticker = filename.split('_')[0]\n",
    "        ticker_list.append(ticker)\n",
    "        \n",
    "        # import csv, sort by date so percent change works, drop unneeded columns,\n",
    "        # rename columns, calculate moving averages, calulate percent changes, drop na's\n",
    "        df = pd.read_csv(f\"../data/predict/{ticker}_daily.csv\")\n",
    "        df.sort_index(inplace=True, ascending=False)\n",
    "        df = df.drop(['5. adjusted close', '7. dividend amount', '8. split coefficient','SMA','EMA'], axis=1)\n",
    "        df.columns = ['date','open','high','low','close','volume','rsi']\n",
    "\n",
    "        # moving averages, convert to percentage of close\n",
    "        df['sma'] = df.iloc[:,3].rolling(window=50).mean()/df.iloc[:,3]\n",
    "        df['ema'] = df.iloc[:,3].ewm(span=21).mean()/df.iloc[:,3]\n",
    "\n",
    "        # percent change\n",
    "        df['open'] = df['open'].pct_change()\n",
    "        df['high'] = df['high'].pct_change()\n",
    "        df['low'] = df['low'].pct_change()\n",
    "        df['close'] = df['close'].pct_change()\n",
    "        df['volume'] = df['volume'].pct_change()\n",
    "        df = df.dropna()\n",
    "\n",
    "        # zscore\n",
    "        df['open'] =zscore(df['open'], window=window_size)\n",
    "        df['high'] = zscore(df['high'], window=window_size)\n",
    "        df['low'] = zscore(df['low'], window=window_size)\n",
    "        df['close'] = zscore(df['close'], window=window_size)\n",
    "        df['volume'] = zscore(df['volume'], window=window_size)\n",
    "        df['rsi'] = zscore(df['rsi'], window=window_size)\n",
    "        df['sma'] = zscore(df['sma'], window=window_size)\n",
    "        df['ema'] = zscore(df['ema'], window=window_size)\n",
    "        df = df.dropna()\n",
    "\n",
    "        # write data and describe to csv\n",
    "        df.to_csv(f\"../data/predict/{ticker}_{window_size}_processed.csv\")\n",
    "\n",
    "ticker_list = set(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting window size: 20\n",
      "starting window size: 320\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {}\n",
    "\n",
    "# iterating through the window sizes provided in the list above\n",
    "for window_size in window_sizes:\n",
    "    print(f\"starting window size: {window_size}\")\n",
    "    \n",
    "    # iterating through the list of processed files\n",
    "    for ticker in ticker_list:\n",
    "        # empty dataframe for this ticker's flattened data\n",
    "        flattened_df = pd.DataFrame()\n",
    "        df = pd.read_csv(f\"../data/predict/{ticker}_{window_size}_processed.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "        \n",
    "        # iterating through grouped rows (window size)\n",
    "        for i in range(df.shape[0]-window_size-1, df.shape[0]-window_size+1):\n",
    "            # resetting the index each time so column names align\n",
    "            df_window = df.iloc[i:i+window_size,].reset_index(drop=True)\n",
    "            # stats dict\n",
    "            if i == (df.shape[0]-window_size):\n",
    "                stats_dict[ticker] = {'open': {'mean': df_window['open'].mean(), 'std': df_window['open'].std()},\n",
    "                                      'high': {'mean': df_window['high'].mean(), 'std': df_window['high'].std()},\n",
    "                                      'low': {'mean': df_window['low'].mean(), 'std': df_window['low'].std()},\n",
    "                                      'close': {'mean': df_window['close'].mean(), 'std': df_window['close'].std()}}\n",
    "            # mapping the index as a string so it can be concatenated\n",
    "            df_window.index = df_window.index.map(str)\n",
    "            # unstacking the window to one row\n",
    "            df_window = df_window.unstack().to_frame().sort_index(level=1).T\n",
    "            # renaming the columns\n",
    "            df_window.columns = df_window.columns.map('_'.join)\n",
    "            # concatenating the flattened row to the dataframe\n",
    "            flattened_df = pd.concat([flattened_df, df_window], axis=0)\n",
    "            \n",
    "                \n",
    "        # writing the flattened dataframe for this ticker and window size to csv\n",
    "        flattened_df.to_csv(f\"../data/predict/{ticker}_{window_size}_flattened.csv\")\n",
    "        #print(f\"{ticker} {window_size} flattened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date that data is available for in ../data/predict/QQQ_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for QQQ.\n",
      "Finished elu-20 for QQQ.\n",
      "Starting linear-20 for QQQ.\n",
      "Finished linear-20 for QQQ.\n",
      "Starting selu-20 for QQQ.\n",
      "Finished selu-20 for QQQ.\n",
      "Starting tanh-20 for QQQ.\n",
      "Finished tanh-20 for QQQ.\n",
      "Latest date that data is available for in ../data/predict/QQQ_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for QQQ.\n",
      "Finished elu-320 for QQQ.\n",
      "Starting linear-320 for QQQ.\n",
      "Finished linear-320 for QQQ.\n",
      "Starting selu-320 for QQQ.\n",
      "Finished selu-320 for QQQ.\n",
      "Starting tanh-320 for QQQ.\n",
      "Finished tanh-320 for QQQ.\n",
      "Latest date that data is available for in ../data/predict/XLV_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLV.\n",
      "Finished elu-20 for XLV.\n",
      "Starting linear-20 for XLV.\n",
      "Finished linear-20 for XLV.\n",
      "Starting selu-20 for XLV.\n",
      "Finished selu-20 for XLV.\n",
      "Starting tanh-20 for XLV.\n",
      "Finished tanh-20 for XLV.\n",
      "Latest date that data is available for in ../data/predict/XLV_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLV.\n",
      "Finished elu-320 for XLV.\n",
      "Starting linear-320 for XLV.\n",
      "Finished linear-320 for XLV.\n",
      "Starting selu-320 for XLV.\n",
      "Finished selu-320 for XLV.\n",
      "Starting tanh-320 for XLV.\n",
      "Finished tanh-320 for XLV.\n",
      "Latest date that data is available for in ../data/predict/XLB_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLB.\n",
      "Finished elu-20 for XLB.\n",
      "Starting linear-20 for XLB.\n",
      "Finished linear-20 for XLB.\n",
      "Starting selu-20 for XLB.\n",
      "Finished selu-20 for XLB.\n",
      "Starting tanh-20 for XLB.\n",
      "Finished tanh-20 for XLB.\n",
      "Latest date that data is available for in ../data/predict/XLB_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLB.\n",
      "Finished elu-320 for XLB.\n",
      "Starting linear-320 for XLB.\n",
      "Finished linear-320 for XLB.\n",
      "Starting selu-320 for XLB.\n",
      "Finished selu-320 for XLB.\n",
      "Starting tanh-320 for XLB.\n",
      "Finished tanh-320 for XLB.\n",
      "Latest date that data is available for in ../data/predict/GDX_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for GDX.\n",
      "Finished elu-20 for GDX.\n",
      "Starting linear-20 for GDX.\n",
      "Finished linear-20 for GDX.\n",
      "Starting selu-20 for GDX.\n",
      "Finished selu-20 for GDX.\n",
      "Starting tanh-20 for GDX.\n",
      "Finished tanh-20 for GDX.\n",
      "Latest date that data is available for in ../data/predict/GDX_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for GDX.\n",
      "Finished elu-320 for GDX.\n",
      "Starting linear-320 for GDX.\n",
      "Finished linear-320 for GDX.\n",
      "Starting selu-320 for GDX.\n",
      "Finished selu-320 for GDX.\n",
      "Starting tanh-320 for GDX.\n",
      "Finished tanh-320 for GDX.\n",
      "Latest date that data is available for in ../data/predict/XLE_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLE.\n",
      "Finished elu-20 for XLE.\n",
      "Starting linear-20 for XLE.\n",
      "Finished linear-20 for XLE.\n",
      "Starting selu-20 for XLE.\n",
      "Finished selu-20 for XLE.\n",
      "Starting tanh-20 for XLE.\n",
      "Finished tanh-20 for XLE.\n",
      "Latest date that data is available for in ../data/predict/XLE_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLE.\n",
      "Finished elu-320 for XLE.\n",
      "Starting linear-320 for XLE.\n",
      "Finished linear-320 for XLE.\n",
      "Starting selu-320 for XLE.\n",
      "Finished selu-320 for XLE.\n",
      "Starting tanh-320 for XLE.\n",
      "Finished tanh-320 for XLE.\n",
      "Latest date that data is available for in ../data/predict/SPY_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for SPY.\n",
      "Finished elu-20 for SPY.\n",
      "Starting linear-20 for SPY.\n",
      "Finished linear-20 for SPY.\n",
      "Starting selu-20 for SPY.\n",
      "Finished selu-20 for SPY.\n",
      "Starting tanh-20 for SPY.\n",
      "Finished tanh-20 for SPY.\n",
      "Latest date that data is available for in ../data/predict/SPY_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for SPY.\n",
      "Finished elu-320 for SPY.\n",
      "Starting linear-320 for SPY.\n",
      "Finished linear-320 for SPY.\n",
      "Starting selu-320 for SPY.\n",
      "Finished selu-320 for SPY.\n",
      "Starting tanh-320 for SPY.\n",
      "Finished tanh-320 for SPY.\n",
      "Latest date that data is available for in ../data/predict/JETS_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for JETS.\n",
      "Finished elu-20 for JETS.\n",
      "Starting linear-20 for JETS.\n",
      "Finished linear-20 for JETS.\n",
      "Starting selu-20 for JETS.\n",
      "Finished selu-20 for JETS.\n",
      "Starting tanh-20 for JETS.\n",
      "Finished tanh-20 for JETS.\n",
      "Latest date that data is available for in ../data/predict/JETS_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for JETS.\n",
      "Finished elu-320 for JETS.\n",
      "Starting linear-320 for JETS.\n",
      "Finished linear-320 for JETS.\n",
      "Starting selu-320 for JETS.\n",
      "Finished selu-320 for JETS.\n",
      "Starting tanh-320 for JETS.\n",
      "Finished tanh-320 for JETS.\n",
      "Latest date that data is available for in ../data/predict/IEMG_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for IEMG.\n",
      "Finished elu-20 for IEMG.\n",
      "Starting linear-20 for IEMG.\n",
      "Finished linear-20 for IEMG.\n",
      "Starting selu-20 for IEMG.\n",
      "Finished selu-20 for IEMG.\n",
      "Starting tanh-20 for IEMG.\n",
      "Finished tanh-20 for IEMG.\n",
      "Latest date that data is available for in ../data/predict/IEMG_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for IEMG.\n",
      "Finished elu-320 for IEMG.\n",
      "Starting linear-320 for IEMG.\n",
      "Finished linear-320 for IEMG.\n",
      "Starting selu-320 for IEMG.\n",
      "Finished selu-320 for IEMG.\n",
      "Starting tanh-320 for IEMG.\n",
      "Finished tanh-320 for IEMG.\n",
      "Latest date that data is available for in ../data/predict/SLV_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for SLV.\n",
      "Finished elu-20 for SLV.\n",
      "Starting linear-20 for SLV.\n",
      "Finished linear-20 for SLV.\n",
      "Starting selu-20 for SLV.\n",
      "Finished selu-20 for SLV.\n",
      "Starting tanh-20 for SLV.\n",
      "Finished tanh-20 for SLV.\n",
      "Latest date that data is available for in ../data/predict/SLV_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for SLV.\n",
      "Finished elu-320 for SLV.\n",
      "Starting linear-320 for SLV.\n",
      "Finished linear-320 for SLV.\n",
      "Starting selu-320 for SLV.\n",
      "Finished selu-320 for SLV.\n",
      "Starting tanh-320 for SLV.\n",
      "Finished tanh-320 for SLV.\n",
      "Latest date that data is available for in ../data/predict/XLK_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLK.\n",
      "Finished elu-20 for XLK.\n",
      "Starting linear-20 for XLK.\n",
      "Finished linear-20 for XLK.\n",
      "Starting selu-20 for XLK.\n",
      "Finished selu-20 for XLK.\n",
      "Starting tanh-20 for XLK.\n",
      "Finished tanh-20 for XLK.\n",
      "Latest date that data is available for in ../data/predict/XLK_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLK.\n",
      "Finished elu-320 for XLK.\n",
      "Starting linear-320 for XLK.\n",
      "Finished linear-320 for XLK.\n",
      "Starting selu-320 for XLK.\n",
      "Finished selu-320 for XLK.\n",
      "Starting tanh-320 for XLK.\n",
      "Finished tanh-320 for XLK.\n",
      "Latest date that data is available for in ../data/predict/EFA_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for EFA.\n",
      "Finished elu-20 for EFA.\n",
      "Starting linear-20 for EFA.\n",
      "Finished linear-20 for EFA.\n",
      "Starting selu-20 for EFA.\n",
      "Finished selu-20 for EFA.\n",
      "Starting tanh-20 for EFA.\n",
      "Finished tanh-20 for EFA.\n",
      "Latest date that data is available for in ../data/predict/EFA_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for EFA.\n",
      "Finished elu-320 for EFA.\n",
      "Starting linear-320 for EFA.\n",
      "Finished linear-320 for EFA.\n",
      "Starting selu-320 for EFA.\n",
      "Finished selu-320 for EFA.\n",
      "Starting tanh-320 for EFA.\n",
      "Finished tanh-320 for EFA.\n",
      "Latest date that data is available for in ../data/predict/IEF_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for IEF.\n",
      "Finished elu-20 for IEF.\n",
      "Starting linear-20 for IEF.\n",
      "Finished linear-20 for IEF.\n",
      "Starting selu-20 for IEF.\n",
      "Finished selu-20 for IEF.\n",
      "Starting tanh-20 for IEF.\n",
      "Finished tanh-20 for IEF.\n",
      "Latest date that data is available for in ../data/predict/IEF_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for IEF.\n",
      "Finished elu-320 for IEF.\n",
      "Starting linear-320 for IEF.\n",
      "Finished linear-320 for IEF.\n",
      "Starting selu-320 for IEF.\n",
      "Finished selu-320 for IEF.\n",
      "Starting tanh-320 for IEF.\n",
      "Finished tanh-320 for IEF.\n",
      "Latest date that data is available for in ../data/predict/LQD_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for LQD.\n",
      "Finished elu-20 for LQD.\n",
      "Starting linear-20 for LQD.\n",
      "Finished linear-20 for LQD.\n",
      "Starting selu-20 for LQD.\n",
      "Finished selu-20 for LQD.\n",
      "Starting tanh-20 for LQD.\n",
      "Finished tanh-20 for LQD.\n",
      "Latest date that data is available for in ../data/predict/LQD_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for LQD.\n",
      "Finished elu-320 for LQD.\n",
      "Starting linear-320 for LQD.\n",
      "Finished linear-320 for LQD.\n",
      "Starting selu-320 for LQD.\n",
      "Finished selu-320 for LQD.\n",
      "Starting tanh-320 for LQD.\n",
      "Finished tanh-320 for LQD.\n",
      "Latest date that data is available for in ../data/predict/FXI_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for FXI.\n",
      "Finished elu-20 for FXI.\n",
      "Starting linear-20 for FXI.\n",
      "Finished linear-20 for FXI.\n",
      "Starting selu-20 for FXI.\n",
      "Finished selu-20 for FXI.\n",
      "Starting tanh-20 for FXI.\n",
      "Finished tanh-20 for FXI.\n",
      "Latest date that data is available for in ../data/predict/FXI_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for FXI.\n",
      "Finished elu-320 for FXI.\n",
      "Starting linear-320 for FXI.\n",
      "Finished linear-320 for FXI.\n",
      "Starting selu-320 for FXI.\n",
      "Finished selu-320 for FXI.\n",
      "Starting tanh-320 for FXI.\n",
      "Finished tanh-320 for FXI.\n",
      "Latest date that data is available for in ../data/predict/BND_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for BND.\n",
      "Finished elu-20 for BND.\n",
      "Starting linear-20 for BND.\n",
      "Finished linear-20 for BND.\n",
      "Starting selu-20 for BND.\n",
      "Finished selu-20 for BND.\n",
      "Starting tanh-20 for BND.\n",
      "Finished tanh-20 for BND.\n",
      "Latest date that data is available for in ../data/predict/BND_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for BND.\n",
      "Finished elu-320 for BND.\n",
      "Starting linear-320 for BND.\n",
      "Finished linear-320 for BND.\n",
      "Starting selu-320 for BND.\n",
      "Finished selu-320 for BND.\n",
      "Starting tanh-320 for BND.\n",
      "Finished tanh-320 for BND.\n",
      "Latest date that data is available for in ../data/predict/XLF_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLF.\n",
      "Finished elu-20 for XLF.\n",
      "Starting linear-20 for XLF.\n",
      "Finished linear-20 for XLF.\n",
      "Starting selu-20 for XLF.\n",
      "Finished selu-20 for XLF.\n",
      "Starting tanh-20 for XLF.\n",
      "Finished tanh-20 for XLF.\n",
      "Latest date that data is available for in ../data/predict/XLF_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLF.\n",
      "Finished elu-320 for XLF.\n",
      "Starting linear-320 for XLF.\n",
      "Finished linear-320 for XLF.\n",
      "Starting selu-320 for XLF.\n",
      "Finished selu-320 for XLF.\n",
      "Starting tanh-320 for XLF.\n",
      "Finished tanh-320 for XLF.\n",
      "Latest date that data is available for in ../data/predict/XLI_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLI.\n",
      "Finished elu-20 for XLI.\n",
      "Starting linear-20 for XLI.\n",
      "Finished linear-20 for XLI.\n",
      "Starting selu-20 for XLI.\n",
      "Finished selu-20 for XLI.\n",
      "Starting tanh-20 for XLI.\n",
      "Finished tanh-20 for XLI.\n",
      "Latest date that data is available for in ../data/predict/XLI_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLI.\n",
      "Finished elu-320 for XLI.\n",
      "Starting linear-320 for XLI.\n",
      "Finished linear-320 for XLI.\n",
      "Starting selu-320 for XLI.\n",
      "Finished selu-320 for XLI.\n",
      "Starting tanh-320 for XLI.\n",
      "Finished tanh-320 for XLI.\n",
      "Latest date that data is available for in ../data/predict/EEM_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for EEM.\n",
      "Finished elu-20 for EEM.\n",
      "Starting linear-20 for EEM.\n",
      "Finished linear-20 for EEM.\n",
      "Starting selu-20 for EEM.\n",
      "Finished selu-20 for EEM.\n",
      "Starting tanh-20 for EEM.\n",
      "Finished tanh-20 for EEM.\n",
      "Latest date that data is available for in ../data/predict/EEM_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for EEM.\n",
      "Finished elu-320 for EEM.\n",
      "Starting linear-320 for EEM.\n",
      "Finished linear-320 for EEM.\n",
      "Starting selu-320 for EEM.\n",
      "Finished selu-320 for EEM.\n",
      "Starting tanh-320 for EEM.\n",
      "Finished tanh-320 for EEM.\n",
      "Latest date that data is available for in ../data/predict/VWO_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for VWO.\n",
      "Finished elu-20 for VWO.\n",
      "Starting linear-20 for VWO.\n",
      "Finished linear-20 for VWO.\n",
      "Starting selu-20 for VWO.\n",
      "Finished selu-20 for VWO.\n",
      "Starting tanh-20 for VWO.\n",
      "Finished tanh-20 for VWO.\n",
      "Latest date that data is available for in ../data/predict/VWO_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for VWO.\n",
      "Finished elu-320 for VWO.\n",
      "Starting linear-320 for VWO.\n",
      "Finished linear-320 for VWO.\n",
      "Starting selu-320 for VWO.\n",
      "Finished selu-320 for VWO.\n",
      "Starting tanh-320 for VWO.\n",
      "Finished tanh-320 for VWO.\n",
      "Latest date that data is available for in ../data/predict/XLU_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for XLU.\n",
      "Finished elu-20 for XLU.\n",
      "Starting linear-20 for XLU.\n",
      "Finished linear-20 for XLU.\n",
      "Starting selu-20 for XLU.\n",
      "Finished selu-20 for XLU.\n",
      "Starting tanh-20 for XLU.\n",
      "Finished tanh-20 for XLU.\n",
      "Latest date that data is available for in ../data/predict/XLU_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for XLU.\n",
      "Finished elu-320 for XLU.\n",
      "Starting linear-320 for XLU.\n",
      "Finished linear-320 for XLU.\n",
      "Starting selu-320 for XLU.\n",
      "Finished selu-320 for XLU.\n",
      "Starting tanh-320 for XLU.\n",
      "Finished tanh-320 for XLU.\n",
      "Latest date that data is available for in ../data/predict/TLT_20_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-20 for TLT.\n",
      "Finished elu-20 for TLT.\n",
      "Starting linear-20 for TLT.\n",
      "Finished linear-20 for TLT.\n",
      "Starting selu-20 for TLT.\n",
      "Finished selu-20 for TLT.\n",
      "Starting tanh-20 for TLT.\n",
      "Finished tanh-20 for TLT.\n",
      "Latest date that data is available for in ../data/predict/TLT_320_flattened.csv is 2021-12-03 (should be latest trading day).\n",
      "Starting elu-320 for TLT.\n",
      "Finished elu-320 for TLT.\n",
      "Starting linear-320 for TLT.\n",
      "Finished linear-320 for TLT.\n",
      "Starting selu-320 for TLT.\n",
      "Finished selu-320 for TLT.\n",
      "Starting tanh-320 for TLT.\n",
      "Finished tanh-320 for TLT.\n"
     ]
    }
   ],
   "source": [
    "forecast_dict = {}\n",
    "\n",
    "for ticker in ticker_list:\n",
    "\n",
    "    forecast_dict[ticker] = {}\n",
    "\n",
    "    for window_size in [20, 320]:\n",
    "\n",
    "        onlyfiles = [f for f in listdir('./results') if isfile(join('./results', f))]\n",
    "        onlyfiles = list(filter(lambda thisfilename: f\"-{window_size}-\" in thisfilename, onlyfiles))\n",
    "\n",
    "        # import csv, sort by date so percent change works, drop unneeded columns,\n",
    "        # rename columns, calculate moving averages, calulate percent changes, drop na's\n",
    "        df = pd.read_csv(f\"../data/predict/{ticker}_{window_size}_flattened.csv\")\n",
    "        df_daily = pd.read_csv(f\"../data/predict/{ticker}_daily.csv\")\n",
    "        df_daily = df_daily.drop(['5. adjusted close', '6. volume', '7. dividend amount', '8. split coefficient','SMA','EMA','RSI'], axis=1)\n",
    "        df_daily.columns = ['date','open','high','low','close']\n",
    "        print(f\"Latest date that data is available for in ../data/predict/{ticker}_{window_size}_flattened.csv is {df_daily.date[0]} (should be latest trading day).\")\n",
    "\n",
    "        # features to use\n",
    "        items = [\"close\", \"ema\", \"high\", \"low\", \"open\", \"rsi\", \"sma\", \"volume\"]\n",
    "        day_counts = [f\"_{i}\" for i in range(1, window_size)]\n",
    "        FEATURE_COLUMNS = []\n",
    "        for day_count in day_counts:\n",
    "            for item in items:\n",
    "                FEATURE_COLUMNS.append(f\"{item}{day_count}\")\n",
    "\n",
    "        df_pred = df[FEATURE_COLUMNS]\n",
    "\n",
    "        # Get samples to predict\n",
    "        samples_to_predict = np.array(df_pred)\n",
    "\n",
    "        # Convert into Numpy array\n",
    "        samples_to_predict = samples_to_predict.reshape((samples_to_predict.shape[0], 1, samples_to_predict.shape[1]))\n",
    "\n",
    "        # File path\n",
    "        for model_filepath in onlyfiles:\n",
    "            print(f\"Starting {model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]} for {ticker}.\")\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]] = {'window_size': window_size, 'tomorrow_forecast_open': None, 'tomorrow_forecast_high': None, 'tomorrow_forecast_low': None, 'tomorrow_forecast_close': None,\n",
    "                                    'today_forecast_open': None, 'today_forecast_high': None, 'today_forecast_low': None, 'today_forecast_close': None,\n",
    "                                    'today_actual_open': None, 'today_actual_high': None, 'today_actual_low': None, 'today_actual_close': None, \n",
    "                                    'today_error_open': None, 'today_error_high': None, 'today_error_low': None, 'today_error_close': None}\n",
    "            model = load_model(f\"./results/{model_filepath}\", compile=True)\n",
    "            # Predict\n",
    "            predictions = model.predict(samples_to_predict)\n",
    "            \n",
    "            linear_df = pd.DataFrame(predictions)\n",
    "            linear_df.columns = ['close','high','low','open']\n",
    "            linear_df.index = ['today','tomorrow']\n",
    "\n",
    "            linear_df.close = linear_df.close*stats_dict[ticker]['close']['std'] + stats_dict[ticker]['close']['mean']\n",
    "            linear_df.high = linear_df.high*stats_dict[ticker]['high']['std'] + stats_dict[ticker]['high']['mean']\n",
    "            linear_df.low = linear_df.low*stats_dict[ticker]['low']['std'] + stats_dict[ticker]['low']['mean']\n",
    "            linear_df.open = linear_df.open*stats_dict[ticker]['open']['std'] + stats_dict[ticker]['open']['mean']\n",
    "\n",
    "            linear_df = linear_df[['open','high','low','close']]\n",
    "            \n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['tomorrow_forecast_open'] = df_daily[['open']].iloc[0,][0] + (df_daily[['open']].iloc[0,][0] * (linear_df[['open']].iloc[1,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['tomorrow_forecast_high'] = df_daily[['high']].iloc[0,][0] + (df_daily[['high']].iloc[0,][0] * (linear_df[['high']].iloc[1,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['tomorrow_forecast_low'] = df_daily[['low']].iloc[0,][0] + (df_daily[['low']].iloc[0,][0] * (linear_df[['low']].iloc[1,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['tomorrow_forecast_close'] = df_daily[['close']].iloc[0,][0] + (df_daily[['close']].iloc[0,][0] * (linear_df[['close']].iloc[1,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_open'] = df_daily[['open']].iloc[1,][0] + (df_daily[['open']].iloc[1,][0] * (linear_df[['open']].iloc[0,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_high'] = df_daily[['high']].iloc[1,][0] + (df_daily[['high']].iloc[1,][0] * (linear_df[['high']].iloc[0,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_low'] = df_daily[['low']].iloc[1,][0] + (df_daily[['low']].iloc[1,][0] * (linear_df[['low']].iloc[0,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_close'] = df_daily[['close']].iloc[1,][0] + (df_daily[['close']].iloc[1,][0] * (linear_df[['close']].iloc[0,][0]/100))\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_open'] = df_daily[['open']].iloc[0,][0]\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_high'] = df_daily[['high']].iloc[0,][0]\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_low'] = df_daily[['low']].iloc[0,][0]\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_close'] = df_daily[['close']].iloc[0,][0]\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_error_open'] = abs((forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_open'] - forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_open']) / forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_open'] * 100)\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_error_high'] = abs((forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_high'] - forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_high']) / forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_high'] * 100)\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_error_low'] = abs((forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_low'] - forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_low']) / forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_low'] * 100)\n",
    "            forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_error_close'] = abs((forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_forecast_close'] - forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_close']) / forecast_dict[ticker][model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]]['today_actual_close'] * 100)\n",
    "            \n",
    "            print(f\"Finished {model_filepath.split('-')[7] + '-' + model_filepath.split('-')[3]} for {ticker}.\")\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "    pd.DataFrame(forecast_dict[ticker]).to_csv(f\"../data/predict_tomorrow/{ticker}_{df_daily.date[0]}_daily_forecast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4c1afcaa0824698e49fb009c9da9eaf010fa52d2eadd2a196450101a9336fb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('beta_lactamase': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
