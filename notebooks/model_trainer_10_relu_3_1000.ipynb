{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5665 - mean_absolute_error: 0.9445\n",
      "Epoch 00001: val_loss improved from inf to 0.54935, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 179s 3ms/sample - loss: 0.5665 - mean_absolute_error: 0.9446 - val_loss: 0.5493 - val_mean_absolute_error: 0.9255\n",
      "Epoch 2/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5612 - mean_absolute_error: 0.9381\n",
      "Epoch 00002: val_loss improved from 0.54935 to 0.54773, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 142s 2ms/sample - loss: 0.5612 - mean_absolute_error: 0.9380 - val_loss: 0.5477 - val_mean_absolute_error: 0.9233\n",
      "Epoch 3/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5584 - mean_absolute_error: 0.9349\n",
      "Epoch 00003: val_loss improved from 0.54773 to 0.54629, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.5585 - mean_absolute_error: 0.9350 - val_loss: 0.5463 - val_mean_absolute_error: 0.9218\n",
      "Epoch 4/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5556 - mean_absolute_error: 0.9315\n",
      "Epoch 00004: val_loss improved from 0.54629 to 0.54597, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.5555 - mean_absolute_error: 0.9315 - val_loss: 0.5460 - val_mean_absolute_error: 0.9212\n",
      "Epoch 5/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5521 - mean_absolute_error: 0.9274\n",
      "Epoch 00005: val_loss improved from 0.54597 to 0.54119, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.5521 - mean_absolute_error: 0.9273 - val_loss: 0.5412 - val_mean_absolute_error: 0.9157\n",
      "Epoch 6/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5479 - mean_absolute_error: 0.9224\n",
      "Epoch 00006: val_loss improved from 0.54119 to 0.54118, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.5479 - mean_absolute_error: 0.9224 - val_loss: 0.5412 - val_mean_absolute_error: 0.9157\n",
      "Epoch 7/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5439 - mean_absolute_error: 0.9174\n",
      "Epoch 00007: val_loss improved from 0.54118 to 0.53892, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 131s 2ms/sample - loss: 0.5439 - mean_absolute_error: 0.9174 - val_loss: 0.5389 - val_mean_absolute_error: 0.9130\n",
      "Epoch 8/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5387 - mean_absolute_error: 0.9114\n",
      "Epoch 00008: val_loss improved from 0.53892 to 0.53865, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 131s 2ms/sample - loss: 0.5387 - mean_absolute_error: 0.9113 - val_loss: 0.5387 - val_mean_absolute_error: 0.9126\n",
      "Epoch 9/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5332 - mean_absolute_error: 0.9045\n",
      "Epoch 00009: val_loss improved from 0.53865 to 0.53768, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 127s 2ms/sample - loss: 0.5332 - mean_absolute_error: 0.9045 - val_loss: 0.5377 - val_mean_absolute_error: 0.9116\n",
      "Epoch 10/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5275 - mean_absolute_error: 0.8975\n",
      "Epoch 00010: val_loss improved from 0.53768 to 0.53631, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 134s 2ms/sample - loss: 0.5275 - mean_absolute_error: 0.8975 - val_loss: 0.5363 - val_mean_absolute_error: 0.9101\n",
      "Epoch 11/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5213 - mean_absolute_error: 0.8900\n",
      "Epoch 00011: val_loss improved from 0.53631 to 0.53550, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 132s 2ms/sample - loss: 0.5213 - mean_absolute_error: 0.8900 - val_loss: 0.5355 - val_mean_absolute_error: 0.9087\n",
      "Epoch 12/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5150 - mean_absolute_error: 0.8823\n",
      "Epoch 00012: val_loss improved from 0.53550 to 0.53305, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.5149 - mean_absolute_error: 0.8822 - val_loss: 0.5331 - val_mean_absolute_error: 0.9059\n",
      "Epoch 13/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5088 - mean_absolute_error: 0.8747\n",
      "Epoch 00013: val_loss improved from 0.53305 to 0.53187, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.5087 - mean_absolute_error: 0.8746 - val_loss: 0.5319 - val_mean_absolute_error: 0.9046\n",
      "Epoch 14/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5036 - mean_absolute_error: 0.8682\n",
      "Epoch 00014: val_loss did not improve from 0.53187\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.5036 - mean_absolute_error: 0.8682 - val_loss: 0.5321 - val_mean_absolute_error: 0.9045\n",
      "Epoch 15/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4974 - mean_absolute_error: 0.8605\n",
      "Epoch 00015: val_loss did not improve from 0.53187\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4975 - mean_absolute_error: 0.8606 - val_loss: 0.5347 - val_mean_absolute_error: 0.9074\n",
      "Epoch 16/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4934 - mean_absolute_error: 0.8556\n",
      "Epoch 00016: val_loss improved from 0.53187 to 0.53079, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.4934 - mean_absolute_error: 0.8556 - val_loss: 0.5308 - val_mean_absolute_error: 0.9029\n",
      "Epoch 17/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4897 - mean_absolute_error: 0.8508\n",
      "Epoch 00017: val_loss improved from 0.53079 to 0.53034, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4897 - mean_absolute_error: 0.8508 - val_loss: 0.5303 - val_mean_absolute_error: 0.9027\n",
      "Epoch 18/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4854 - mean_absolute_error: 0.8456\n",
      "Epoch 00018: val_loss did not improve from 0.53034\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4854 - mean_absolute_error: 0.8456 - val_loss: 0.5319 - val_mean_absolute_error: 0.9039\n",
      "Epoch 19/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4824 - mean_absolute_error: 0.8417\n",
      "Epoch 00019: val_loss did not improve from 0.53034\n",
      "67485/67485 [==============================] - 134s 2ms/sample - loss: 0.4823 - mean_absolute_error: 0.8417 - val_loss: 0.5304 - val_mean_absolute_error: 0.9020\n",
      "Epoch 20/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4792 - mean_absolute_error: 0.8376\n",
      "Epoch 00020: val_loss improved from 0.53034 to 0.52898, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 139s 2ms/sample - loss: 0.4792 - mean_absolute_error: 0.8377 - val_loss: 0.5290 - val_mean_absolute_error: 0.9005\n",
      "Epoch 21/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4762 - mean_absolute_error: 0.8339\n",
      "Epoch 00021: val_loss did not improve from 0.52898\n",
      "67485/67485 [==============================] - 140s 2ms/sample - loss: 0.4762 - mean_absolute_error: 0.8339 - val_loss: 0.5296 - val_mean_absolute_error: 0.9010\n",
      "Epoch 22/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4742 - mean_absolute_error: 0.8312\n",
      "Epoch 00022: val_loss improved from 0.52898 to 0.52810, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4742 - mean_absolute_error: 0.8313 - val_loss: 0.5281 - val_mean_absolute_error: 0.8993\n",
      "Epoch 23/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4719 - mean_absolute_error: 0.8282\n",
      "Epoch 00023: val_loss did not improve from 0.52810\n",
      "67485/67485 [==============================] - 140s 2ms/sample - loss: 0.4719 - mean_absolute_error: 0.8282 - val_loss: 0.5309 - val_mean_absolute_error: 0.9024\n",
      "Epoch 24/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4697 - mean_absolute_error: 0.8253\n",
      "Epoch 00024: val_loss did not improve from 0.52810\n",
      "67485/67485 [==============================] - 139s 2ms/sample - loss: 0.4697 - mean_absolute_error: 0.8253 - val_loss: 0.5300 - val_mean_absolute_error: 0.9014\n",
      "Epoch 25/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4678 - mean_absolute_error: 0.8228\n",
      "Epoch 00025: val_loss did not improve from 0.52810\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4678 - mean_absolute_error: 0.8228 - val_loss: 0.5299 - val_mean_absolute_error: 0.9011\n",
      "Epoch 26/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4666 - mean_absolute_error: 0.8215\n",
      "Epoch 00026: val_loss did not improve from 0.52810\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4665 - mean_absolute_error: 0.8214 - val_loss: 0.5296 - val_mean_absolute_error: 0.9006\n",
      "Epoch 27/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4648 - mean_absolute_error: 0.8191\n",
      "Epoch 00027: val_loss improved from 0.52810 to 0.52759, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4648 - mean_absolute_error: 0.8191 - val_loss: 0.5276 - val_mean_absolute_error: 0.8983\n",
      "Epoch 28/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4632 - mean_absolute_error: 0.8169\n",
      "Epoch 00028: val_loss did not improve from 0.52759\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4631 - mean_absolute_error: 0.8169 - val_loss: 0.5282 - val_mean_absolute_error: 0.8994\n",
      "Epoch 29/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4622 - mean_absolute_error: 0.8156\n",
      "Epoch 00029: val_loss improved from 0.52759 to 0.52667, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4621 - mean_absolute_error: 0.8155 - val_loss: 0.5267 - val_mean_absolute_error: 0.8970\n",
      "Epoch 30/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4610 - mean_absolute_error: 0.8140\n",
      "Epoch 00030: val_loss improved from 0.52667 to 0.52503, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4611 - mean_absolute_error: 0.8141 - val_loss: 0.5250 - val_mean_absolute_error: 0.8951\n",
      "Epoch 31/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4596 - mean_absolute_error: 0.8124\n",
      "Epoch 00031: val_loss improved from 0.52503 to 0.52469, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4596 - mean_absolute_error: 0.8124 - val_loss: 0.5247 - val_mean_absolute_error: 0.8949\n",
      "Epoch 32/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4588 - mean_absolute_error: 0.8109\n",
      "Epoch 00032: val_loss did not improve from 0.52469\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4589 - mean_absolute_error: 0.8110 - val_loss: 0.5257 - val_mean_absolute_error: 0.8959\n",
      "Epoch 33/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4579 - mean_absolute_error: 0.8098\n",
      "Epoch 00033: val_loss did not improve from 0.52469\n",
      "67485/67485 [==============================] - 139s 2ms/sample - loss: 0.4579 - mean_absolute_error: 0.8098 - val_loss: 0.5249 - val_mean_absolute_error: 0.8949\n",
      "Epoch 34/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4573 - mean_absolute_error: 0.8089\n",
      "Epoch 00034: val_loss did not improve from 0.52469\n",
      "67485/67485 [==============================] - 140s 2ms/sample - loss: 0.4573 - mean_absolute_error: 0.8089 - val_loss: 0.5255 - val_mean_absolute_error: 0.8957\n",
      "Epoch 35/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4561 - mean_absolute_error: 0.8075\n",
      "Epoch 00035: val_loss improved from 0.52469 to 0.52410, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4561 - mean_absolute_error: 0.8075 - val_loss: 0.5241 - val_mean_absolute_error: 0.8939\n",
      "Epoch 36/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4553 - mean_absolute_error: 0.8064\n",
      "Epoch 00036: val_loss improved from 0.52410 to 0.52318, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 139s 2ms/sample - loss: 0.4553 - mean_absolute_error: 0.8064 - val_loss: 0.5232 - val_mean_absolute_error: 0.8929\n",
      "Epoch 37/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4543 - mean_absolute_error: 0.8050\n",
      "Epoch 00037: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 139s 2ms/sample - loss: 0.4544 - mean_absolute_error: 0.8050 - val_loss: 0.5259 - val_mean_absolute_error: 0.8964\n",
      "Epoch 38/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4535 - mean_absolute_error: 0.8042\n",
      "Epoch 00038: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4537 - mean_absolute_error: 0.8044 - val_loss: 0.5238 - val_mean_absolute_error: 0.8934\n",
      "Epoch 39/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4526 - mean_absolute_error: 0.8027\n",
      "Epoch 00039: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 134s 2ms/sample - loss: 0.4526 - mean_absolute_error: 0.8027 - val_loss: 0.5246 - val_mean_absolute_error: 0.8943\n",
      "Epoch 40/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4524 - mean_absolute_error: 0.8024\n",
      "Epoch 00040: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4524 - mean_absolute_error: 0.8025 - val_loss: 0.5247 - val_mean_absolute_error: 0.8944\n",
      "Epoch 41/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.8012\n",
      "Epoch 00041: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4516 - mean_absolute_error: 0.8011 - val_loss: 0.5252 - val_mean_absolute_error: 0.8950\n",
      "Epoch 42/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4513 - mean_absolute_error: 0.8009\n",
      "Epoch 00042: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4513 - mean_absolute_error: 0.8010 - val_loss: 0.5259 - val_mean_absolute_error: 0.8954\n",
      "Epoch 43/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4511 - mean_absolute_error: 0.8005\n",
      "Epoch 00043: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4511 - mean_absolute_error: 0.8005 - val_loss: 0.5247 - val_mean_absolute_error: 0.8940\n",
      "Epoch 44/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4504 - mean_absolute_error: 0.7996\n",
      "Epoch 00044: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 138s 2ms/sample - loss: 0.4504 - mean_absolute_error: 0.7996 - val_loss: 0.5258 - val_mean_absolute_error: 0.8954\n",
      "Epoch 45/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4496 - mean_absolute_error: 0.7985\n",
      "Epoch 00045: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 136s 2ms/sample - loss: 0.4495 - mean_absolute_error: 0.7984 - val_loss: 0.5250 - val_mean_absolute_error: 0.8948\n",
      "Epoch 46/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4493 - mean_absolute_error: 0.7980\n",
      "Epoch 00046: val_loss did not improve from 0.52318\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.4493 - mean_absolute_error: 0.7979 - val_loss: 0.5252 - val_mean_absolute_error: 0.8945\n",
      "Epoch 47/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4487 - mean_absolute_error: 0.7974\n",
      "Epoch 00047: val_loss improved from 0.52318 to 0.52263, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-relu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 134s 2ms/sample - loss: 0.4487 - mean_absolute_error: 0.7975 - val_loss: 0.5226 - val_mean_absolute_error: 0.8917\n",
      "Epoch 48/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4483 - mean_absolute_error: 0.7969\n",
      "Epoch 00048: val_loss did not improve from 0.52263\n",
      "67485/67485 [==============================] - 137s 2ms/sample - loss: 0.4482 - mean_absolute_error: 0.7968 - val_loss: 0.5246 - val_mean_absolute_error: 0.8941\n",
      "Epoch 49/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4480 - mean_absolute_error: 0.7964\n",
      "Epoch 00049: val_loss did not improve from 0.52263\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.4480 - mean_absolute_error: 0.7964 - val_loss: 0.5236 - val_mean_absolute_error: 0.8928\n",
      "Epoch 50/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4475 - mean_absolute_error: 0.7957\n",
      "Epoch 00050: val_loss did not improve from 0.52263\n",
      "67485/67485 [==============================] - 135s 2ms/sample - loss: 0.4476 - mean_absolute_error: 0.7958 - val_loss: 0.5245 - val_mean_absolute_error: 0.8940\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 1000\n",
    "# 40% dropout\n",
    "DROPOUT = 0.25\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "LAYER_ACTIVATION = \"relu\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
