{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5286 - mean_absolute_error: 0.9016\n",
      "Epoch 00001: val_loss improved from inf to 0.51582, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 33s 490us/sample - loss: 0.5285 - mean_absolute_error: 0.9015 - val_loss: 0.5158 - val_mean_absolute_error: 0.8861\n",
      "Epoch 2/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5151 - mean_absolute_error: 0.8856\n",
      "Epoch 00002: val_loss improved from 0.51582 to 0.51310, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 22s 329us/sample - loss: 0.5150 - mean_absolute_error: 0.8856 - val_loss: 0.5131 - val_mean_absolute_error: 0.8827\n",
      "Epoch 3/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5104 - mean_absolute_error: 0.8800\n",
      "Epoch 00003: val_loss improved from 0.51310 to 0.50934, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 317us/sample - loss: 0.5104 - mean_absolute_error: 0.8800 - val_loss: 0.5093 - val_mean_absolute_error: 0.8784\n",
      "Epoch 4/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.5067 - mean_absolute_error: 0.8756\n",
      "Epoch 00004: val_loss improved from 0.50934 to 0.50631, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 318us/sample - loss: 0.5066 - mean_absolute_error: 0.8754 - val_loss: 0.5063 - val_mean_absolute_error: 0.8744\n",
      "Epoch 5/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.5036 - mean_absolute_error: 0.8719\n",
      "Epoch 00005: val_loss did not improve from 0.50631\n",
      "67485/67485 [==============================] - 21s 312us/sample - loss: 0.5035 - mean_absolute_error: 0.8718 - val_loss: 0.5066 - val_mean_absolute_error: 0.8754\n",
      "Epoch 6/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5002 - mean_absolute_error: 0.8678\n",
      "Epoch 00006: val_loss did not improve from 0.50631\n",
      "67485/67485 [==============================] - 21s 313us/sample - loss: 0.5002 - mean_absolute_error: 0.8678 - val_loss: 0.5077 - val_mean_absolute_error: 0.8770\n",
      "Epoch 7/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4980 - mean_absolute_error: 0.8650\n",
      "Epoch 00007: val_loss did not improve from 0.50631\n",
      "67485/67485 [==============================] - 22s 321us/sample - loss: 0.4979 - mean_absolute_error: 0.8649 - val_loss: 0.5065 - val_mean_absolute_error: 0.8752\n",
      "Epoch 8/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4941 - mean_absolute_error: 0.8607\n",
      "Epoch 00008: val_loss improved from 0.50631 to 0.50527, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 316us/sample - loss: 0.4942 - mean_absolute_error: 0.8608 - val_loss: 0.5053 - val_mean_absolute_error: 0.8733\n",
      "Epoch 9/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4924 - mean_absolute_error: 0.8588\n",
      "Epoch 00009: val_loss improved from 0.50527 to 0.50475, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 315us/sample - loss: 0.4925 - mean_absolute_error: 0.8589 - val_loss: 0.5047 - val_mean_absolute_error: 0.8735\n",
      "Epoch 10/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4901 - mean_absolute_error: 0.8561\n",
      "Epoch 00010: val_loss improved from 0.50475 to 0.50162, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 314us/sample - loss: 0.4902 - mean_absolute_error: 0.8562 - val_loss: 0.5016 - val_mean_absolute_error: 0.8691\n",
      "Epoch 11/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4882 - mean_absolute_error: 0.8536\n",
      "Epoch 00011: val_loss improved from 0.50162 to 0.50134, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 314us/sample - loss: 0.4882 - mean_absolute_error: 0.8536 - val_loss: 0.5013 - val_mean_absolute_error: 0.8691\n",
      "Epoch 12/30\n",
      "67264/67485 [============================>.] - ETA: 0s - loss: 0.4864 - mean_absolute_error: 0.8517\n",
      "Epoch 00012: val_loss improved from 0.50134 to 0.50043, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 21s 316us/sample - loss: 0.4865 - mean_absolute_error: 0.8518 - val_loss: 0.5004 - val_mean_absolute_error: 0.8681\n",
      "Epoch 13/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4842 - mean_absolute_error: 0.8491\n",
      "Epoch 00013: val_loss did not improve from 0.50043\n",
      "67485/67485 [==============================] - 21s 315us/sample - loss: 0.4840 - mean_absolute_error: 0.8489 - val_loss: 0.5015 - val_mean_absolute_error: 0.8692\n",
      "Epoch 14/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4828 - mean_absolute_error: 0.8474\n",
      "Epoch 00014: val_loss improved from 0.50043 to 0.49997, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 22s 327us/sample - loss: 0.4827 - mean_absolute_error: 0.8473 - val_loss: 0.5000 - val_mean_absolute_error: 0.8673\n",
      "Epoch 15/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4813 - mean_absolute_error: 0.8457\n",
      "Epoch 00015: val_loss did not improve from 0.49997\n",
      "67485/67485 [==============================] - 21s 313us/sample - loss: 0.4814 - mean_absolute_error: 0.8457 - val_loss: 0.5003 - val_mean_absolute_error: 0.8677\n",
      "Epoch 16/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4799 - mean_absolute_error: 0.8437\n",
      "Epoch 00016: val_loss did not improve from 0.49997\n",
      "67485/67485 [==============================] - 23s 334us/sample - loss: 0.4798 - mean_absolute_error: 0.8436 - val_loss: 0.5051 - val_mean_absolute_error: 0.8733\n",
      "Epoch 17/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4786 - mean_absolute_error: 0.8424\n",
      "Epoch 00017: val_loss improved from 0.49997 to 0.49866, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 22s 319us/sample - loss: 0.4786 - mean_absolute_error: 0.8424 - val_loss: 0.4987 - val_mean_absolute_error: 0.8655\n",
      "Epoch 18/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4771 - mean_absolute_error: 0.8404\n",
      "Epoch 00018: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 21s 317us/sample - loss: 0.4772 - mean_absolute_error: 0.8405 - val_loss: 0.5011 - val_mean_absolute_error: 0.8686\n",
      "Epoch 19/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4753 - mean_absolute_error: 0.8381\n",
      "Epoch 00019: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 22s 322us/sample - loss: 0.4753 - mean_absolute_error: 0.8381 - val_loss: 0.4988 - val_mean_absolute_error: 0.8657\n",
      "Epoch 20/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4742 - mean_absolute_error: 0.8370\n",
      "Epoch 00020: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 21s 316us/sample - loss: 0.4742 - mean_absolute_error: 0.8370 - val_loss: 0.4996 - val_mean_absolute_error: 0.8665\n",
      "Epoch 21/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4724 - mean_absolute_error: 0.8349\n",
      "Epoch 00021: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 23s 340us/sample - loss: 0.4724 - mean_absolute_error: 0.8349 - val_loss: 0.4996 - val_mean_absolute_error: 0.8666\n",
      "Epoch 22/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4713 - mean_absolute_error: 0.8338\n",
      "Epoch 00022: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 22s 324us/sample - loss: 0.4713 - mean_absolute_error: 0.8338 - val_loss: 0.5003 - val_mean_absolute_error: 0.8680\n",
      "Epoch 23/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4702 - mean_absolute_error: 0.8324\n",
      "Epoch 00023: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 22s 319us/sample - loss: 0.4702 - mean_absolute_error: 0.8324 - val_loss: 0.5001 - val_mean_absolute_error: 0.8675\n",
      "Epoch 24/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4679 - mean_absolute_error: 0.8297\n",
      "Epoch 00024: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 22s 322us/sample - loss: 0.4679 - mean_absolute_error: 0.8298 - val_loss: 0.4987 - val_mean_absolute_error: 0.8655\n",
      "Epoch 25/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4678 - mean_absolute_error: 0.8293\n",
      "Epoch 00025: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 21s 317us/sample - loss: 0.4679 - mean_absolute_error: 0.8294 - val_loss: 0.5006 - val_mean_absolute_error: 0.8676\n",
      "Epoch 26/30\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4666 - mean_absolute_error: 0.8282\n",
      "Epoch 00026: val_loss did not improve from 0.49866\n",
      "67485/67485 [==============================] - 23s 338us/sample - loss: 0.4666 - mean_absolute_error: 0.8282 - val_loss: 0.4988 - val_mean_absolute_error: 0.8656\n",
      "Epoch 27/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4657 - mean_absolute_error: 0.8268\n",
      "Epoch 00027: val_loss improved from 0.49866 to 0.49841, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 22s 324us/sample - loss: 0.4657 - mean_absolute_error: 0.8268 - val_loss: 0.4984 - val_mean_absolute_error: 0.8655\n",
      "Epoch 28/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4645 - mean_absolute_error: 0.8259\n",
      "Epoch 00028: val_loss did not improve from 0.49841\n",
      "67485/67485 [==============================] - 22s 323us/sample - loss: 0.4645 - mean_absolute_error: 0.8259 - val_loss: 0.4996 - val_mean_absolute_error: 0.8668\n",
      "Epoch 29/30\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4635 - mean_absolute_error: 0.8246\n",
      "Epoch 00029: val_loss did not improve from 0.49841\n",
      "67485/67485 [==============================] - 22s 325us/sample - loss: 0.4635 - mean_absolute_error: 0.8245 - val_loss: 0.4992 - val_mean_absolute_error: 0.8663\n",
      "Epoch 30/30\n",
      "67328/67485 [============================>.] - ETA: 0s - loss: 0.4628 - mean_absolute_error: 0.8234\n",
      "Epoch 00030: val_loss improved from 0.49841 to 0.49780, saving model to results\\2021-11-30_MIXED-huber_loss-adam-LSTM-linear-layers-4-units-40-b.h5\n",
      "67485/67485 [==============================] - 23s 334us/sample - loss: 0.4627 - mean_absolute_error: 0.8233 - val_loss: 0.4978 - val_mean_absolute_error: 0.8645\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 4\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 40\n",
    "# 40% dropout\n",
    "DROPOUT = 0.25\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "LAYER_ACTIVATION = \"linear\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6SUlEQVR4nO3deVxWdfr/8dfFLoKogIqi4r6k5oLmkqWZ5VJaWVZmU01lzeS0TONMzbealplfzXz7VtO0L7bZZpblpJW5t5iKqLmvqYAGuIALO1y/P84hkUABubm54Xo+Hjy477NepzvvN+d8zvl8RFUxxhhjyuLn7QKMMcbUXhYSxhhjymUhYYwxplwWEsYYY8plIWGMMaZcFhLGGGPKZSFhTDUQkTdF5O8VXHa3iFx4ptsxpiZYSBhjjCmXhYQxxphyWUiYesO9zDNNRH4UkeMi8rqINBeRL0TkqIgsEJEmJZYfJyIbRSRDRJaISLcS8/qISKK73odASKl9XSIia911vxeRXlWs+VYR2SEih0Rkjoi0dKeLiDwtImkickRE1otID3feGBHZ5NaWIiJ/qtJ/MGOwkDD1zwRgJNAZuBT4AvgrEI3z7+FOABHpDLwP3O3Omwf8V0SCRCQI+BR4B2gKfORuF3fdPsB04DYgEngZmCMiwZUpVEQuAB4HJgIxwB7gA3f2RcB57nFEuMscdOe9DtymquFAD2BRZfZrTEkWEqa++Y+qpqpqCvANsEJV16hqDjAb6OMudzUwV1W/VtV84EmgATAYGAgEAs+oar6qzgJWldjHFOBlVV2hqoWq+haQ665XGdcB01U1UVVzgfuBQSISB+QD4UBXQFR1s6rud9fLB7qLSCNVPayqiZXcrzG/sJAw9U1qidfZZbwPc1+3xPnLHQBVLQKSgFbuvBQ9uXfMPSVetwXudS81ZYhIBtDaXa8yStdwDOdsoZWqLgKeA54H0kTkFRFp5C46ARgD7BGRpSIyqJL7NeYXFhLGlG0fzpc94LQB4HzRpwD7gVbutGJtSrxOAv6hqo1L/ISq6vtnWENDnMtXKQCq+qyq9gO641x2muZOX6Wq44FmOJfFZlZyv8b8wkLCmLLNBMaKyAgRCQTuxblk9D2wHCgA7hSRQBG5AhhQYt1XgdtF5By3gbmhiIwVkfBK1vA+cJOI9HbbM/4fzuWx3SLS391+IHAcyAGK3DaT60Qkwr1MdgQoOoP/Dqaes5AwpgyquhWYDPwHOIDTyH2pquapah5wBXAjcAin/eKTEusmALfiXA46DOxwl61sDQuAB4GPcc5eOgDXuLMb4YTRYZxLUgeB/3XnXQ/sFpEjwO04bRvGVInYoEPGGGPKY2cSxhhjymUhYYwxplwWEsYYY8plIWGMMaZcAd4uoLpERUVpXFyct8swxhifsnr16gOqGl3e/DoTEnFxcSQkJHi7DGOM8SkisudU8+1ykzHGmHJ5NCREZJSIbHW7Or6vjPk3iki626XyWhG5xZ3e1u2Gea3bVfPtnqzTGGNM2Tx2uUlE/HE6HxsJJAOrRGSOqm4qteiHqjq11LT9wCBVzRWRMGCDu+4+T9VrjDHm1zzZJjEA2KGquwBE5ANgPFA6JH7F7fagWDBVPOPJz88nOTmZnJycqqzuU0JCQoiNjSUwMNDbpRhj6hBPhkQrnN4wiyUD55Sx3AQROQ/YBtyjqkkAItIamAt0BKaVdRYhIlNw+u6nTZs2pWeTnJxMeHg4cXFxnNxhZ92iqhw8eJDk5GTatWvn7XKMMXWItxuu/wvEqWov4GvgreIZqprkTu8I3CAizUuvrKqvqGq8qsZHR//6Dq6cnBwiIyPrdEAAiAiRkZH14ozJGFOzPBkSKTj97xeLdaf9QlUPuiNuAbwG9Cu9EfcMYgMwtCpF1PWAKFZfjtMYU7M8GRKrgE4i0s4dE/gaYE7JBUQkpsTbccBmd3qsiDRwXzcBzgW2eqLIgsIiUo/kkJ1X4InNG2OMT/NYSKhqATAV+Arny3+mqm4UkUdFZJy72J3uLa7rcAagv9Gd3g1Y4U5fCjypqus9UacIpB3JITPbMyGRkZHBCy+8UOn1xowZQ0ZGRvUXZIwxlVBnxpOIj4/X0k9cb968mW7dup123R1pxwDo2CzsNEtW3u7du7nkkkvYsGHDSdMLCgoICKje+wYqerzGGFNMRFaranx58+tMtxxnIizYn/SjeRQWKf5+1Xtt/7777mPnzp307t2bwMBAQkJCaNKkCVu2bGHbtm1cdtllJCUlkZOTw1133cWUKVOAE92MHDt2jNGjR3Puuefy/fff06pVKz777DMaNGhQrXUaY0xZ6k1IPPLfjWzad6TMeYVFSk5+ISGB/pUKie4tG/G3S8865TJPPPEEGzZsYO3atSxZsoSxY8eyYcOGX25VnT59Ok2bNiU7O5v+/fszYcIEIiMjT9rG9u3bef/993n11VeZOHEiH3/8MZMnT65wncYYU1X1JiROxd9PQPDImURpAwYMOOlZhmeffZbZs2cDkJSUxPbt238VEu3ataN3794A9OvXj927d3u0RmOMKVZvQuJ0f/HvTD9GUZHSqXm4R+to2LDhL6+XLFnCggULWL58OaGhoQwbNqzMZx2Cg4N/ee3v7092drZHazTGmGLefpiu1ggLDiA7v5CCwqJq3W54eDhHjx4tc15mZiZNmjQhNDSULVu28MMPP1Trvo0x5kzVmzOJ0wkLDiAVOJ5bQERoULVtNzIykiFDhtCjRw8aNGhA8+YnHhwfNWoUL730Et26daNLly4MHDiw2vZrjDHVwW6BdRWpsmnfEZqEBtGqiW/eOWS3wBpjKut0t8Da5SaXnwgNgwM4lmtPXhtjTDELiRLCgv3JLSgkv6B62yWMMcZXWUiUEBbsNNEcs36cjDEGsJA4SfHDdMdyLCSMMQYsJE4iIoQFB3A8t4C60qBvjDFnwkKilLDgAPIKi8ir5ucljDHGF1lIlNKwuF2imu5yqmpX4QDPPPMMWVlZ1VKHMcZUhYVEKcEBfgT6+3G8mtolLCSMMb7Mnrgupbhd4miO0y5xpsOCluwqfOTIkTRr1oyZM2eSm5vL5ZdfziOPPMLx48eZOHEiycnJFBYW8uCDD5Kamsq+ffsYPnw4UVFRLF68uJqO0BhjKq7+hMQX98HPFRvcrkVREU3yi9Ag/1OHRIueMPqJU26rZFfh8+fPZ9asWaxcuRJVZdy4cSxbtoz09HRatmzJ3LlzAadPp4iICJ566ikWL15MVFRUhQ/TGGOqk11uKoO/GwyFRdV7h9P8+fOZP38+ffr0oW/fvmzZsoXt27fTs2dPvv76a/7yl7/wzTffEBERUa37NcaYqqo/ZxKn+Yu/JD8g+ecjhAT4ExfV8LTLV5Sqcv/993Pbbbf9al5iYiLz5s3jgQceYMSIETz00EPVtl9jjKkqO5MoR3U9L1Gyq/CLL76Y6dOnc+yYM6Z2SkoKaWlp7Nu3j9DQUCZPnsy0adNITEz81brGGOMN9edMopLCggM4dDyP7PxCQoOq/p+pZFfho0ePZtKkSQwaNMjZR1gYM2bMYMeOHUybNg0/Pz8CAwN58cUXAZgyZQqjRo2iZcuW1nBtjPEKj3YVLiKjgH8D/sBrqvpEqfk3Av8LpLiTnlPV10SkN/Ai0AgoBP6hqh+eal9n2lV4afmFRWzef4QWESE0Cw+p0jZqmnUVboyprNN1Fe6xMwkR8QeeB0YCycAqEZmjqptKLfqhqk4tNS0L+I2qbheRlsBqEflKVTM8VW9pgf5+hAT6cyyngGaeHdHUGGNqLU+2SQwAdqjqLlXNAz4AxldkRVXdpqrb3df7gDQg2mOVliMsOICsvEKKrB8nY0w95cmQaAUklXif7E4rbYKI/Cgis0SkdemZIjIACAJ2ljFviogkiEhCenp6mUWcyeW0sOAAilTJyius8jZqinVIaIzxBG/f3fRfIE5VewFfA2+VnCkiMcA7wE2q+qse91T1FVWNV9X46Ohfn2iEhIRw8ODBKn+Bhgb7I1Druw5XVQ4ePEhIiG+0nRhjfIcn725KAUqeGcRyooEaAFU9WOLta8C/it+ISCNgLvA/qvpDVQqIjY0lOTmZ8s4yKuLQ0VwOA4fDg6u8jZoQEhJCbGyst8swxtQxngyJVUAnEWmHEw7XAJNKLiAiMaq63307DtjsTg8CZgNvq+qsqhYQGBhIu3btqro6AHO+3MKry3ax7m8X/dJDrDHG1Bceu9ykqgXAVOArnC//maq6UUQeFZFx7mJ3ishGEVkH3Anc6E6fCJwH3Cgia92f3p6q9VSGdIiioEhZufuQN3ZvjDFe5dE/jVV1HjCv1LSHSry+H7i/jPVmADM8WVtF9WvbhCB/P5bvPMjwLs28XY4xxtQobzdc13oNgvzp06Yx3+884O1SjDGmxllIVMCQjlFs3HeEjKw8b5dijDE1ykKiAgZ3iEQVfth18PQLG2NMHWIhUQG9YhsTGuTP9zstJIwx9YuFRAUEBfgxoF1Tvtth7RLGmPrFQgJg5auQdepbXAd3iGRn+nFSj+TUUFHGGON9FhIHtsOX98Mr58P+deUuNriDM870crvkZIypRywkojrBb7+EokJ4bSQkvlPmYt1jGhHRINAuORlj6hULCYDYeLhtGbQdBHOmwpw/QP7Jl5X8/IRB7SNZvDWdzOx8LxVqjDE1y0KiWMMomPwJDL0XEt+G6RfD4T0nLTLl/PZkZOXx51nrrGtuY0y9YCFRkp8/jHgIrnkfDv3ktFNsX/DL7L5tmnDf6K58tTGV6d/t9l6dxhhTQywkytJ1DExZDI1awbtXwpInoMgZzuLmc9sxsntzHp+3mcS9h71cqDHGeJaFRHkiO8DNX8PZ18CSx+G9iZB1CBHhyavOJqZxCFPfTeTwceuqwxhTd1lInEpQKFz2Iox9CnYtgZfPh31riGgQyAuT+nHgWB5/nLmWoiJrnzDG1E0WEqcjAv1vdm6T1UJ4YywkJ9AzNoIHL+3O4q3pvLTsV8NvG2NMnWAhUVGx8XDrIgiLdtop0jYz+Zw2XHp2S578aqt1/meMqZMsJCojvAVc/yn4B8M7lyMZe3j8ip7ERTbkzvfXkH4019sVGmNMtbKQqKym7eD62ZCfDW9fRljeQV6Y3JfM7Hzu/nANhdY+YYypQywkqqJ5d7huFhxLgxlX0DWikMcu68F3Ow7y7MLt3q7OGGOqjYVEVbXuD9e8Cwe2wbsTmdirKVf2i+XZRdv5Znu6t6szxphqYSFxJjoMhwmvQ0oCfDiZx8Z2onOzcO7+YC0/Z1qX4sYY3+fRkBCRUSKyVUR2iMh9Zcy/UUTSRWSt+3NLiXlfikiGiHzuyRrPWPdxcOmzsHMRDT7/Hc9fezbZ+YX84f1ECgqLvF2dMcacEY+FhIj4A88Do4HuwLUi0r2MRT9U1d7uz2slpv8vcL2n6qtWfa+Hi/4Bmz6l48oHefzyHqzafZgHP9toHQEaY3xagAe3PQDYoaq7AETkA2A8sKkiK6vqQhEZ5rHqqtvgqZB9GL55kvENmrB12LW8sGQn0WFB/PGiLt6uzhhjqsSTl5taAUkl3ie700qbICI/isgsEWldmR2IyBQRSRCRhPT0WtBYfMEDEH8zfPcM0xp+wdXxrXl20Q7e/O4nb1dmjDFV4u2G6/8CcaraC/gaeKsyK6vqK6oar6rx0dHRHimwUkRgzJPQ40pk4cP8v+aLuKhbMx75fBNz1u3zdnXGGFNpngyJFKDkmUGsO+0XqnpQVYsfU34N6OfBemqGnx9c/hKcdTn+C//GC03eY2DbCO6duZZl22rB2Y4xxlSCJ0NiFdBJRNqJSBBwDTCn5AIiElPi7ThgswfrqTn+gTBhOgy5m4DE6bzd8Gl6RAdw+4zVrE3K8HZ1xhhTYR4LCVUtAKYCX+F8+c9U1Y0i8qiIjHMXu1NENorIOuBO4Mbi9UXkG+AjYISIJIvIxZ6q1SP8/GDkI3DJMwTuWszMoEfpEnqcm95YyY60Y96uzhhjKkTqyi2a8fHxmpCQ4O0yyrZ9AXx0AwVB4VyXPY2kgDg+/v1gYiIaeGZ/xZ+piGe2b4ypM0RktarGlzff2w3X9UOnC+G3XxIgwnt+D9EjZzXXv76yeke1K8iDnYtg7p/g6R7wRFv47A7YtRSKCqtvP8aYesXOJGpSZgq8NxFN28wDBTezKeYy3r3lHEKDqvi4SnYG7FgAW+fB9q8h9wgENIAOF0BwGGyZC3nHIDwGekyAnldBzNl2hmGM+cXpziQsJGpazhH46EbYuZDnC8aT0P73vHLDAAL9K3hSl5EEW7+ArXNh97dQVAANo6HzKOgyBtoPc4ZdBac7861fwPqPnBApyofITtBrIvS8Epq299RRGmN8hIVEbVSYD/P+BKvf5LPCwSzp+jD/ujqewPwjTvfjx1Ld3+7r4+nO74wkOLDV2UZUZycUuoxxRs3z8z/1PrMOwabPYP0s2POtM61VvHN2cdblEN7cs8dsjKmVLCRqK1X47t+w4G9kaiihkk8g+b9ezi8Qwpo7w6aGtYC2g51giOpY9X1nJsOGj+HHjyB1PYgfxA11Lkl1uxRCm1Z928YYn2IhUdttmctP387kqz1F+IU14+rh/YiIjnWCoWE0NGji2TaEtM2w4RPYMAsO7QK/AOgwwgmMrmMgONxz+zbGeJ2FhI9YsjWNO95NpHFoEG/e1J9OzWv4y1kV9q9zwmLDbDiSDAEh0Okip/2i00UQ6KFbdo0xXmMh4UM2pGRy05uryM0v5JXfxDOwfaR3CikqguSVziWpjbOdNpGgMKdRPKozRHWCyI7Oj12aqpqCPCjIhpAIb1di6jkLCR+TdCiLm95cxd6DWfzfxLO59OyW3i2osMBp6F4/C/Yuh8O7nTuqioVGuoHRyWkniewI0V2d33arbdkK8+GNMXD0Z7hjxYm70YzxAgsJH5SRlceUt1ezcvch/jqmK7cObY/Uli/cwnw4vAcO7oCD253fB9zXx1JPLNdnMlzyb/D35JAlPmrBI/DtU87rEX+DoX/0bj2mXjtdSNi/4FqocWgQb988gHtnruP/zdvCvowcHrykO/5+tSAo/AOdM4aojsCok+flHHFCY+Ns+P5ZOJYOV70BQQ29UmqttGspfPu0E6LHD8C3z0C/G+2ynam1rFuOWiok0J//XNuHW85tx5vf7+b3764mJ7+Wd68R0gha9YWLHoNLnoYdX8Nb4+D4QW9XVjtkHYLZt0FkBxj9L7jwYcg7Csue9HZlxpTLQqIW8/MTHrikOw9d0p35m1K59tUfOFSd/T15UvxvYeI7kLoBpl/ktGXUZ6rw2VTn7GHC687ZVbNu0HsSrHrVuYRnTC1kIeEDfntuO16Y1JeN+45w9cvLST2S4+2SKqbbJfCbz5wvxtcvcm6xra8SXne6UrnwYWjZ+8T0YX91HmZc9HdvVWbMKVlI+IjRPWN486b+7MvI5qqXlpN0KMvbJVVMm4Hw26+cJ8ffGAs7F3u7opqXugm++h/nIcWBvz95XkQrGPg7WD+zfoeoqbUsJHzI4A5RzLjlHDKz87nqpeW+M3hRs65wy9fQuA28e5XTHUh9kZ8NH9/sPLl++UvOYFSlDbnbebJ+wcM1XZ0xp2Uh4WP6tGnCB1MGUlCkXP3ycjakZHq7pIpp1BJumgetz4FPboHv/+PtimrG/AchbRNc9hKENSt7mQaNYeifnPFA6uOZlqnVLCR8ULeYRsy8bSDBAX5c++oPrN5zyNslVUyDxjD5Y+h+Gcx/wLkEU1Tk7ao8Z8s8p1F64B3OwFOnMuBWiGgDXz9Ut/+bGJ9jD9P5sJSMbK579QdSj+Ty6m/iObdTlLdLqpiiIvjyPlj5stNdeVQn58nt0Kbu7+KfKOd3g8an7wq9so7+DEkrnDOb8BbVu22AI/vhxcFOm8MtCyEg+PTrrPsQZk+BK16DXldVf03GlMGeuK7j0o7m8JvXV7Ir/TjPTerDRWd54AvPE1Rhxcuw7j3IOgxZByH/eDkLixMgrfpBu/Oh3XnQvEfZ1/dPtb+0zc4dRlu/gJTVznS/QKfH24G/O/muozNRVATvXAbJq2DKUojuXPH1XjkPcjJhakLFgqWkwgJnYCnriNFUgoVEPZCRlccNb6xiQ0omT008m/G9W3m7pKrJz3YeOMs6+Oufo/thz3Kn+w+ABk2h3VAnMNoNcx5QK911SWE+7PneHclvHmS4zyK06gddRkObQbD5v7BmhjPMa5vBTlh0HXtmZy7fPu00Ql/6LPS7oXLr7lgIM66Aix+HQb8//fLFUlbDJ7c5/61G/8vpube2dOViajWvhoSIjAL+DfgDr6nqE6Xm3wj8L5DiTnpOVV9z590APOBO/7uqvnWqfdXnkAA4llvALW+tYsVPh/jHZT2ZdE4bb5fkGUf2wU/LnJ9dS50uzQHCW7qBcZ7zF/i2L2H7fOevcv9gpwfbrmOcYV5LX17KyXSCYsVLkLHXuQvrnNudrjMq20tr8mrn4cGuY+Gqt6r2Rf32eNj/I9y19vT7L8x3nthe9r/OcYU1h32JznGOfcq53GVOSN/m9G7caaQzoqPxXkiIiD+wDRgJJAOrgGtVdVOJZW4E4lV1aql1mwIJQDygwGqgn6oeLm9/9T0kAHLyC/n9u4ks2pLGtIu78LvzO+BXG/p78hRVZ6Ckn5aeCI4stwuQ0Ch33O/R0GF4xfqPKixwzjh+eBH2fg9B4U5QnDPlxHjgRUWQfdjpPj3rgPP7+AH3Jx22feUEw+3fOLe1VsW+tfDK+XDuH+HCv5W/3IHt8MkUJxR6Xe2cQQSHO2G38DFnAKmLHoW+N1bu0lx1K8x3LvXtW+PUum+N898wNAoaRrm/I0u9d9ujwppVT99fGUmw9AlY+x6oe2NAxwvh/Pugdf8z374P82ZIDAIeVtWL3ff3A6jq4yWWuZGyQ+JaYJiq3ua+fxlYoqrvl7c/CwlHXkER9360jv+u28c57Zryryt70TaynnSwV1QEaRuhIBda9jmzS0b71jhhseFjKCp0Gtez3bYTLevuI3FCoVErp9+qM/3imXUzbJkLdyY6tw+XpAqrXnNurw0MgUuegbMuO3mZQz/Bf+90gjNuKFz6b+eSnKcVFcKBbW4guD8/r4cCt5eAkAjns2nYzL2UeMDp2yvrwIllSosb6oR1t3GV71b9WLrT4+6q15z3/W+BAVNg06fw3bOQfajeh4U3Q+JKYJSq3uK+vx44p2QguCHxOJCOc9Zxj6omicifgBBV/bu73INAtqo+WWofU4ApAG3atOm3Z4/1fwOgqnyUkMxjn2+ioEj586gu3DAorm6fVXjKkf1Olxppm52/bhtGn/hLt2H0id8NmlZvt+iHd8N/4qH3tTCuxDMlR/bBZ3c4z1R0HAnjnyv/7ixVWPMOfPUAFObC8P9xnviuSJ1ZhyA5wWl8z0x2xhDRQicEigqcoPzltTs9P9v571R8A0JQGMT0dm4IaNnH6fyxSbuyL8GpQt7xk0Pj+AE4/BOs/8j57xEUDj0uh96TofWAU1/Ky8mE75+DH16A/Cynj6zz74PGrU8sk3vMuUW5OCw6jIBh9znbrm5FRc7ddBs/cbrUb9wGGrd1f7eBiNYQHFb9+62A2h4SkcAxVc0VkduAq1X1goqGREl2JvFr+zOzuf+T9SzZms6AOOesIi6qnpxV1AVfuLcJ/26589T6ho/h8z9CYR5c9HenE8WKtHkc2Q9z73Xu7GrZB8Y9By16nJhfWOA88Je88kQwHNzhzBM/p73HPwDE3zk78yt+7VfidYDTjXx01xOBENmxem5dLipyLv+tedc5A8jPcga56j0Jzr4WGsWcWDY/G1a+6pw9ZB+G7uNh+AOnvsMs95hzpvH9s87ZTXWFhapzeW3DJ073+UdSnCGBI2Kdy1+FuScvHxp5cmg0bQddxp58fB5Qqy83lVreHzikqhF2uan6qCqzVifz6OebyC8sYtrFXblpsJ1V+ITjB+HZ3hDb37mUtWGW8/rylyt/6UjV+aKaNw1yMpwzCj9/JxRSEk/89d8wGmIHOI26rQc4ZwJe+gu3TLlHYeOnsPZdZ6RE8XO+1PtcB9kZsPRfcHSfM23Eg05gVXjbpcPiAmesjyZxzpd2gyanD2VVJ3A3fOz8HN7t3Gbd8ULnVusuo5x2o6Iipw0rY69z113G3pN/MpOcy2/iD50vhr43ONvwwCBe3gyJAJxLSCNw7l5aBUxS1Y0llolR1f3u68uBv6jqQLfhejXQ1100EafhutxHiy0kTu3nzBz+Ons9i7akEd+2Cf+6shfto2vRP35TtmVPwiK3EXrYfTDknjP7osg65DzI+OOHzjZb9HLCILa/EwyN2/rOrbMHdzphsfZ9JxjACbgL/wZx51Z9u6XDolhgqHMWEBHrhEZE6xPvg8Ng23znclL6FufLvf35TjB0HVv5mxhUnbO5te86Z1DH05wzuj6Toe/1ztlGNfH2LbBjgGdwboGdrqr/EJFHgQRVnSMijwPjgALgEPA7Vd3irvtb4K/upv6hqm+cal8WEqenqsxek8LDczaSW1DEtIu7cNOQdrVjxDtTtrws5/bW7uMq91fx6WQmO5c36sKDd0WFzh1u4uc8bFldIZeX5XzhZya7P0nuj/v+eHqpFQTaDoYeV0C38RAWXT11FOY7z/okvuU8RwPuWc4N0Hk0BASd0ebtYTrzK6lHcvif2etZsDmNvm0a89ykvrRsXAe+LIypSfnZkJniBEfWQefhTE8/l5Kx13mmZ80Mp42jYbTTNtP3hirfvWYhYcqkqny2dh8PfrqByLAgZt4+iGbhId4uyxhTEUWFsGMBrH7LeXA0qjP8fnmVzqJOFxIVesJGRO4SkUbieF1EEkXkokpXY2oNEeGyPq1487cDSDuay/WvreSwrwyNakx95+c2aF/7HtyzEcY/77G2pIo+hvlbVT0CXAQ0Aa4Hnjj1KsYX9GvbhNd+E89PB49zwxsrOZqT7+2SjDGV0SgGYvt5bPMVDYniiBoDvOPeoWStnXXE4I5RvHhdXzbtO8LNbyaQnVfo7ZKMMbVERUNitYjMxwmJr0QkHLCRUeqQEd2a8/TVvVm15xC3zVhNboEFhTGm4iFxM3Af0F9Vs4BA4CaPVWW84tKzW/LEFT1Zti2dO99fQ0Gh/R1gTH1X0ZAYBGxV1QwRmYzThbePDK5sKuPq/m146JLufLUxlT/P+pGiorpx95sxpmoqGhIvAlkicjZwL7ATeNtjVRmv+u257bh3ZGc+WZPCQ3M2UFdukzbGVF5Fn+8vUFUVkfE4AwO9LiI3e7Iw411TL+jIsbwCXl66i4bBAdw3qiviK901GGOqTUVD4qjbQd/1wFAR8cNplzB1lIhw36iuZOUW8vLSXYQFBfCHEZ28XZYxpoZVNCSuBibhPC/xs4i0wRl21NRhIsIj487ieF4B//f1NkTgtvM7EOjvxVHOjDE1qkL/2lX1Z+BdIEJELgFyVNXaJOoBPz/hXxN6MbZnDE/O38bwJ5fw3oq9dousMfVERbvlmAisBK4CJgIr3EGFTD0Q4O/Hc5P68MZN/YkKC+avs9cz/H+X8M7y3eTkW1gYU5dVqIM/EVkHjFTVNPd9NLBAVc/2cH0VZh381QxV5dsdB/j3gu0k7DlM80bB3H5+B64d0IaQwGoYhcwYU6OqpYM/wK84IFwHK7GuqUNEhKGdovno9kG8d+s5xEU25JH/buLcfy7mtW92kZVX4O0SjTHVqKIN11+KyFdA8fChVwPzPFOS8QUiwuAOUQzuEMWKXQf5z6Id/H3uZl5cspNbhrbnxsFxNAiyMwtjfF2Fx5MQkQnAEPftN6o622NVVYFdbvK+1XsO8ezCHSzdlk5cZCj/nNCLc9pHerssY8wp2KBDpsZ9v+MA932ynr2Hsrh+YFv+MrorYcHVP4C7MebMnVGbhIgcFZEjZfwcFZEj1V+uqQsGd4ziy7uHcvO57ZixYg8XP72MZdtKjwdsjPEFpwwJVQ1X1UZl/ISraqOaKtL4ntCgAB68pDuzbh9MSKAfv5m+kmkfrSMzywY1MsaX2B1KxqP6tW3C3DuHcsfwDnyyJoULn17K/I0/e7ssY0wFeTQkRGSUiGwVkR0ict8plpsgIioi8e77IBF5Q0TWi8g6ERnmyTqNZ4UE+jPt4q58dscQosKCmfLOaqa+l8jBY7neLs0YcxoeCwkR8QeeB0YD3YFrRaR7GcuFA3cBK0pMvhVAVXsCI4H/czsVND6sR6sI5kwdwr0jOzN/Yyojn17Gp2tSrCtyY2oxT37xDgB2qOouVc0DPgDGl7HcY8A/gZwS07oDiwDch/gygHJb343vCPT34w8jOvH5nefSpmkod3+4lqteWs76ZBvDypjayJMh0QpIKvE+2Z32CxHpC7RW1bml1l0HjBORABFpB/QDWpfegYhMEZEEEUlIT7e7Z3xJ5+bhfPy7wfxzQk92HzzOuOe/5c+z1pF2NOf0KxtjaozXLuG4l4+ewhnprrTpOKGSADwDfA/8qic5VX1FVeNVNT46OtqD1RpP8PcTru7fhkV/GsatQ9sze00KFzy5lJeX7rReZo2pJTwZEimc/Nd/rDutWDjQA1giIruBgcAcEYlX1QJVvUdVe6vqeKAxsM2DtRovahQSyF/HdGP+PeczsH1THv9iCxc/vYwFm1KtvcIYL/NkSKwCOolIOxEJAq4B5hTPVNVMVY1S1ThVjQN+AMapaoKIhIpIQwARGYkzfOomD9ZqaoF2UQ157Yb+vPXbAQT4+3HL2wn8ZvpKtqUe9XZpxtRbHgsJVS0ApgJfAZuBmaq6UUQeFZFxp1m9GZAoIpuBv+AMm2rqifM7R/PFXUN5+NLurEvKYPS/v+HhORvtllljvMD6bjK12qHjeTz99TbeXbGH4AB/Jg9sw63ntadZeIi3SzOmTrAO/kydsDP9GM8v2sGna1MI9Pfj2gFtuP38DrSIsLAw5kxYSJg6ZfeB47ywZAefJKbgJ8LV/Vtz+7AOtGrcwNulGeOTLCRMnZR0KIsXluxk1mrnUZwr+7Xm98M60LppqJcrM8a3WEiYOi0lI5uXluzkw1VJFKpyRZ9WTL2gI20jG3q7NGN8goWEqRd+zszhpaU7eX/lXgD+MqorNw6Ow89PvFyZMbXbGQ06ZIyvaBERwsPjzmLZn4czpGMUj36+icmvryAlI9vbpRnj0ywkTJ3SvFEIr98Qz+NX9GRtUgajnlnG7DXJ9uS2MVVkIWHqHBHh2gFt+OKuoXRpHs49H67jjvcSOXQ8z9ulGeNzLCRMndU2siEf3jaIP4/qwtebUrn4mWUs3pLm7bKM8SkWEqZO8/cTfj+sI5/eMYSmoUHc9OYq7v9kPcdzC7xdmjE+wULC1AtntYxgzh+GcNt57flg1V7GPPsNq/cc8nZZxtR6FhKm3ggO8Of+Md344NaBFBQqV720nFvfTmDh5lQKCou8XZ4xtVKAtwswpqad0z6SL+8eygtLdvJRQhJfb0qlWXgwV/aLZWJ8a+Ki7EE8Y4rZw3SmXssvLGLRljRmrkpi8dY0ihTOadeUq/u3ZnSPGBoE+Xu7RGM8yp64NqaCUo/kMGt1MjMTkthzMIvwkADGnd2Sq/u3pmerCETs6W1T91hIGFNJqsqKnw7x4aok5q3fT25BEd1iGjExPpbLereiScMgb5doTLWxkDDmDGRm5zNn3T4+Skjix+RMgvz9GNm9OVfFxzK0UzT+1jeU8XEWEsZUk837j/BRQjKz1yRzOCufmIgQJvSN5ar4WOt11vgsCwljqlluQSGLNqfxYUISy7alU6QwsH1TJsZbY7fxPRYSxnjQ/sxsPklMOdHYHRzAhH6x3DA4jnZ2K63xARYSxtQAVWXlT4d4f+Ve5q7fT36hMrxLNDcNacfQTlF2Z5Sptbw6noSIjBKRrSKyQ0TuO8VyE0RERSTefR8oIm+JyHoR2Swi93uyTmPOlIhwTvtInrmmD9/ddwF3jejE+pQj/Gb6Si58ainv/LDH+osyPsljZxIi4g9sA0YCycAq4FpV3VRquXBgLhAETFXVBBGZBIxT1WtEJBTYBAxT1d3l7c/OJExtk1tQyNwf9/PGd7tZn5JJeEgA1/RvzW8GxdlY3KbWON2ZhCe75RgA7FDVXW4hHwDjcb7wS3oM+CcwrcQ0BRqKSADQAMgDjniwVmOqXXCAP1f0jeXyPq1I3HuYN77bzfTvdvP6tz9xYbfmXD+oLYM7RNlttKZW82RItAKSSrxPBs4puYCI9AVaq+pcESkZErNwAmU/EArco6q/6rJTRKYAUwDatGlTvdUbU01EhH5tm9KvbVP2Z2Yz44c9vLdiL/M3pdKiUQjje7fksj6t6BbTyNulGvMrXuvgT0T8gKeAG8uYPQAoBFoCTYBvRGRB8VlJMVV9BXgFnMtNHi3YmGoQE9GAaRd35Q8XdGLh5jRmr0nh9W9/4uVlu+jaIpzL+rRifO+WxEQ08HapxgCeDYkUoHWJ97HutGLhQA9giXvnRwtgjoiMAyYBX6pqPpAmIt8B8cBJIWGMrwoJ9GdsrxjG9orh0PE85v64j9lrUnjiiy3888stDGwXyeV9WzGqRwsahQR6u1xTj3my4ToAp+F6BE44rAImqerGcpZfAvzJbbj+C9BVVW8SkYbuuteo6o/l7c8ark1dsOfgcT5ds4/Za5LZfTCL4AA/LuzenGv6t2ZIhyj8rP3CVDOvNVyraoGITAW+AvyB6aq6UUQeBRJUdc4pVn8eeENENgICvHGqgDCmrmgb2ZC7LuzEnSM6sjYpg0/XpDBn3T7m/riftpGhTBrQhiv7xRIZFuztUk09YQ/TGVPL5RYU8uWGn3l3xV5W/nSIIH8/RvdsweSBbYlv28Qe1DNnxJ64NqYO2ZZ6lPdW7OXj1ckczS2gc/MwrjunLZf3bWVtF6ZKLCSMqYOy8gr4fN1+ZqzYw4/JmTQI9Gfc2S25YXAc3VvarbSm4iwkjKnjfkzO4L0Ve/ls7T6y8wsZ37slf7qoiz3VbSrEQsKYeiIzO59Xlu3k9W9/oqgIrh/UlqnDO9pIeuaULCSMqWd+zszh6a+38dHqJBoGB/D7YR25aUgcIYE2zoX5Na/2AmuMqXktIkL455W9+PLu8xgQ15R/frmF4U8u4aOEJAqL6sYfhabmWEgYU0d1bh7O6zf254MpA2kWHsy0WT8y9tlvWLw1jbpyBcF4noWEMXXcwPaRfHrHEJ6f1Jec/EJuemMVk15dwWdrU8jMyvd2eaaWszYJY+qRvIIi3l+5l+cX7yDtaC7+fsKAuKaM6NaMkd2b0zbShlytb6zh2hjzK0VFytrkDBZuTmXBpjS2ph4FoFOzMEZ0a87I7s3o3bqJjXVRD1hIGGNOK+lQFgs2p7Jgcyordh2ioEhp2jCIC7o249KzW3KejdNdZ1lIGGMqJTM7n2Xb0lmwOZXFW9I4klNAnzaN+ePIzpzb0cKirrGQMMZUWV5BER8nJvOfhdvZl5lD/7gm3DOyM4M7RHm7NFNNLCSMMWcst6CQmauSeG7xDlKP5DKofSR/vKgz/eOaers0c4YsJIwx1SYnv9C9O2onB47lMrRTFPeM7EzfNk28XZqpIgsJY0y1y84rZMYPe3hp6U4OHs9jeJdo7hnZmV6xjb1dmqkkCwljjMcczy3g7eV7eHnZTjKy8unRqhFje7ZkbM8Y2kRaL7S+wELCGONxR3PymZmQzOc/7mPN3gwAeraKYEzPGAuMWs5CwhhTo5IPZ/HF+p+Zu34/a5MyACcwxvZyAsPGuahdLCSMMV6TdCiLLzbsZ+76n1nnBkav2AhG9WjBhd2a06lZmD134WUWEsaYWiHpUBbz1u9n7vr9/JicCUDrpg0Y0bU5F3RtxjntmxIcYGNe1DSvhoSIjAL+DfgDr6nqE+UsNwGYBfRX1QQRuQ6YVmKRXkBfVV1b3r4sJIzxHT9n5rBoSxqLtqTy7Y4D5OQXERrkz9BOUYzo1pzhXZoRHR7s7TLrBa+FhIj4A9uAkUAysAq4VlU3lVouHJgLBAFTVTWh1PyewKeq2uFU+7OQMMY35eQX8v3OAyzcnMaiLWnsz8wB4OzWjbmwazOuH9SWxqE2BKunnC4kAjy47wHADlXd5RbyATAe2FRquceAf3LymUNJ1wIfeKpIY4x3hQT6c0HX5lzQtTmqyqb9R1i0OY2FW9J4asE23lq+h79fdhajesR4u9R6yZODDrUCkkq8T3an/UJE+gKtVXXuKbZzNfB+WTNEZIqIJIhIQnp6+pnWa4zxMhHhrJYR/GFEJz69Ywif/+FcmjcK5vYZifxuxmrSjuZ4u8R6x2sj04mIH/AUcO8pljkHyFLVDWXNV9VXVDVeVeOjo6M9VKkxxlvOahnBp3cMYdrFXVi4JY2RTy1j1upkG361BnkyJFKA1iXex7rTioUDPYAlIrIbGAjMEZGS18auoZyzCGNM/RDo78cdwzsy786hdGoWxp8+WscNb6wi+XCWt0urFzwZEquATiLSTkSCcL7w5xTPVNVMVY1S1ThVjQN+AMYVN1y7ZxoTsfYIYwzQsVkYM28bxCPjziJh9yEufnoZby/fTVGRnVV4ksdCQlULgKnAV8BmYKaqbhSRR0VkXAU2cR6QVNzwbYwxfn7CDYPj+Oru8+jbtgkPfbaRq19Zzs70Y94urc6yh+mMMT5JVZm1OpnHPt9ETkERl/SMISjAD+cBbucpbhHnlfPbmRbo78ewLtEM6RhlY3hjT1wbY+q4tKM5PPb5Zlb+dBBVUODE15r+Mg2cYMnOLyQnv4iYiBCu6NuKCX1jaR8d5p3iawELCWOMKSEnv5CFm9OYtTqJpdvSKVKIb9uEK/vFMrZXDOEhgd4usUZZSBhjTDlSj+Qwe00Ks1YnsyPtGCGBfozuEcOV/WIZ1D4Sv3pwOcpCwhhjTkNVWZecyUcJScxZt4+jOQW0atyAS86O4fxO0fSLa1JnOx+0kDDGmErIyS/k602pzFqdzHc7DlBQpDQI9Gdg+6ac1zmaoZ2i6RDdsM50cW4hYYwxVXQst4Afdh7km+3pfLP9ALsOHAegVeMGDO0UxdBO0QzpGOnTHRBaSBhjTDVJOpTFN9sP8M32dL7dcYCjOQX4CfSKbczFZ7XwyaFaLSSMMcYDCgqLWJecyTfb01m8JY117kBKZ7Vs9MvY3nFRDb1c5elZSBhjTA1IPpzFlxucsb3X7M0AoHtMI8b2imFMzxja1dLAsJAwxpgalpKRzRfr9zNv/X4S3cDo2iKcsT1jGN2zBR2ia8/Y3hYSxhjjRfsysvlyw8/MW7+fhD2HAWds7wu6NGN412YMbB9JSKD3bq+1kDDGmFri58wcFm5JZdHmNL7b6Yzt3SDQnyEdo7igazOGd40mJqJBjdZkIWGMMbVQTn4hy3cdZPGWNBZuTiMlIxuAbjGNuKBrNBd0bUbPVo0JCvDs2HAWEsYYU8upKtvTjrFoSxqLtqSxes9hCouU4AA/esVG0LdNE/q0aULfto1pFh5Srfu2kDDGGB+TmZXPdzsPsHrPYRL3HmZjyhHyCosApz2jb5smv/x0jQkn0L/qZxsWEsYY4+Ny8gvZuC+TxD0ZJO51giP1SC4ADQL9GdGtGc9N6lulbZ8uJAKqVrIxxpiaEhLoT7+2TenXtingXJ5KycgmcW8GiXsOExrkubujLCSMMcbHiAixTUKJbRLKuLNbenRfnm02N8YY49MsJIwxxpTLQsIYY0y5PBoSIjJKRLaKyA4Rue8Uy00QERWR+BLTeonIchHZKCLrRaR6bw42xhhzWh5ruBYRf+B5YCSQDKwSkTmquqnUcuHAXcCKEtMCgBnA9aq6TkQigXxP1WqMMaZsnjyTGADsUNVdqpoHfACML2O5x4B/Ajklpl0E/Kiq6wBU9aCqFnqwVmOMMWXwZEi0ApJKvE92p/1CRPoCrVV1bql1OwMqIl+JSKKI/LmsHYjIFBFJEJGE9PT06qzdGGMMXmy4FhE/4Cng3jJmBwDnAte5vy8XkRGlF1LVV1Q1XlXjo6OjPVqvMcbUR558mC4FaF3ifaw7rVg40ANY4g6+0QKYIyLjcM46lqnqAQARmQf0BRaWt7PVq1cfEJE9Z1BvFHDgDNavbera8UDdO6a6djxQ946prh0P/PqY2p5qYU+GxCqgk4i0wwmHa4BJxTNVNROnWABEZAnwJ1VNEJGdwJ9FJBTIA84Hnj7VzlT1jE4lRCThVP2X+Jq6djxQ946prh0P1L1jqmvHA5U/Jo9dblLVAmAq8BWwGZipqhtF5FH3bOFU6x7GuRS1ClgLJJbRbmGMMcbDPNp3k6rOA+aVmvZQOcsOK/V+Bs5tsMYYY7zEnrg+4RVvF1DN6trxQN07prp2PFD3jqmuHQ9U8pjqzHgSxhhjqp+dSRhjjCmXhYQxxphy1fuQqGgnhL5ERHa7nSKuFRGfG9NVRKaLSJqIbCgxramIfC0i293fTbxZY2WVc0wPi0iK+zmtFZEx3qyxMkSktYgsFpFNbiecd7nTffJzOsXx+PJnFCIiK0VknXtMj7jT24nICvc770MRCTrldupzm4TbCeE2SnRCCFxbuhNCXyMiu4H44ocRfY2InAccA95W1R7utH8Bh1T1CTfMm6jqX7xZZ2WUc0wPA8dU9Ulv1lYVIhIDxKhqottJ52rgMuBGfPBzOsXxTMR3PyMBGqrqMREJBL7F6Uz1j8AnqvqBiLwErFPVF8vbTn0/k6hoJ4SmBqnqMuBQqcnjgbfc12/h/AP2GeUck89S1f2qmui+PorzLFQrfPRzOsXx+Cx1HHPfBro/ClwAzHKnn/Yzqu8hcdpOCH2UAvNFZLWITPF2MdWkuarud1//DDT3ZjHVaKqI/OhejvKJSzOliUgc0Aenu3+f/5xKHQ/48GckIv4ishZIA74GdgIZ7sPOUIHvvPoeEnXVuaraFxgN3OFe6qgz1LlGWheuk74IdAB6A/uB//NqNVUgImHAx8Ddqnqk5Dxf/JzKOB6f/oxUtVBVe+P0nTcA6FrZbdT3kDhdJ4Q+SVVT3N9pwGyc/zl8Xap73bj4+nGal+s5Y6qa6v4jLgJexcc+J/c698fAu6r6iTvZZz+nso7H1z+jYqqaASwGBgGN3YHdoALfefU9JH7phNBt4b8GmOPlms6IiDR0G94QkYY4AzhtOPVaPmEOcIP7+gbgMy/WUi2Kv0xdl+NDn5PbKPo6sFlVnyoxyyc/p/KOx8c/o2gRaey+boBzg85mnLC40l3stJ9Rvb67CcC9pe0ZwB+Yrqr/8G5FZ0ZE2uOcPYDTN9d7vnZMIvI+MAynl+BU4G/Ap8BMoA2wB5ioqj7TEFzOMQ3DuYyhwG7gthLX82s1ETkX+AZYDxS5k/+Kcx3f5z6nUxzPtfjuZ9QLp2HaH+eEYKaqPup+R3wANAXWAJNVNbfc7dT3kDDGGFO++n65yRhjzClYSBhjjCmXhYQxxphyWUgYY4wpl4WEMcaYcllIGFMLiMgwEfnc23UYU5qFhDHGmHJZSBhTCSIy2e2jf62IvOx2oHZMRJ52++xfKCLR7rK9ReQHt3O42cWdw4lIRxFZ4PbznygiHdzNh4nILBHZIiLvuk8BG+NVFhLGVJCIdAOuBoa4naYVAtcBDYEEVT0LWIrzNDXA28BfVLUXzpO8xdPfBZ5X1bOBwTgdx4HT8+jdQHegPTDEw4dkzGkFnH4RY4xrBNAPWOX+kd8ApwO7IuBDd5kZwCciEgE0VtWl7vS3gI/cfrVaqepsAFXNAXC3t1JVk933a4E4nIFijPEaCwljKk6At1T1/pMmijxYarmq9nVTsv+cQuzfp6kF7HKTMRW3ELhSRJrBL+M5t8X5d1Tcq+Yk4FtVzQQOi8hQd/r1wFJ31LNkEbnM3UawiITW5EEYUxn2l4oxFaSqm0TkAZxR//yAfOAO4DgwwJ2XhtNuAU43zC+5IbALuMmdfj3wsog86m7jqho8DGMqxXqBNeYMicgxVQ3zdh3GeIJdbjLGGFMuO5MwxhhTLjuTMMYYUy4LCWOMMeWykDDGGFMuCwljjDHlspAwxhhTrv8PJT3vD9cCkRwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
