{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5283 - mean_absolute_error: 0.9014\n",
      "Epoch 00001: val_loss improved from inf to 0.51469, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 71s 1ms/sample - loss: 0.5290 - mean_absolute_error: 0.9021 - val_loss: 0.5147 - val_mean_absolute_error: 0.8855\n",
      "Epoch 2/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5189 - mean_absolute_error: 0.8899\n",
      "Epoch 00002: val_loss improved from 0.51469 to 0.50979, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 828us/sample - loss: 0.5190 - mean_absolute_error: 0.8900 - val_loss: 0.5098 - val_mean_absolute_error: 0.8803\n",
      "Epoch 3/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5126 - mean_absolute_error: 0.8823\n",
      "Epoch 00003: val_loss improved from 0.50979 to 0.50596, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 823us/sample - loss: 0.5125 - mean_absolute_error: 0.8823 - val_loss: 0.5060 - val_mean_absolute_error: 0.8756\n",
      "Epoch 4/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5055 - mean_absolute_error: 0.8739\n",
      "Epoch 00004: val_loss improved from 0.50596 to 0.50243, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 822us/sample - loss: 0.5055 - mean_absolute_error: 0.8740 - val_loss: 0.5024 - val_mean_absolute_error: 0.8717\n",
      "Epoch 5/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4971 - mean_absolute_error: 0.8638\n",
      "Epoch 00005: val_loss improved from 0.50243 to 0.49715, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 829us/sample - loss: 0.4971 - mean_absolute_error: 0.8638 - val_loss: 0.4971 - val_mean_absolute_error: 0.8656\n",
      "Epoch 6/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4858 - mean_absolute_error: 0.8507\n",
      "Epoch 00006: val_loss improved from 0.49715 to 0.49397, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 835us/sample - loss: 0.4858 - mean_absolute_error: 0.8507 - val_loss: 0.4940 - val_mean_absolute_error: 0.8617\n",
      "Epoch 7/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4708 - mean_absolute_error: 0.8324\n",
      "Epoch 00007: val_loss improved from 0.49397 to 0.48788, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 824us/sample - loss: 0.4708 - mean_absolute_error: 0.8324 - val_loss: 0.4879 - val_mean_absolute_error: 0.8542\n",
      "Epoch 8/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4521 - mean_absolute_error: 0.8102\n",
      "Epoch 00008: val_loss improved from 0.48788 to 0.48484, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 823us/sample - loss: 0.4521 - mean_absolute_error: 0.8103 - val_loss: 0.4848 - val_mean_absolute_error: 0.8508\n",
      "Epoch 9/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4305 - mean_absolute_error: 0.7842\n",
      "Epoch 00009: val_loss improved from 0.48484 to 0.48115, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 821us/sample - loss: 0.4304 - mean_absolute_error: 0.7841 - val_loss: 0.4811 - val_mean_absolute_error: 0.8458\n",
      "Epoch 10/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4084 - mean_absolute_error: 0.7573\n",
      "Epoch 00010: val_loss improved from 0.48115 to 0.48049, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 58s 858us/sample - loss: 0.4084 - mean_absolute_error: 0.7573 - val_loss: 0.4805 - val_mean_absolute_error: 0.8442\n",
      "Epoch 11/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3875 - mean_absolute_error: 0.7318\n",
      "Epoch 00011: val_loss improved from 0.48049 to 0.47720, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 819us/sample - loss: 0.3874 - mean_absolute_error: 0.7317 - val_loss: 0.4772 - val_mean_absolute_error: 0.8407\n",
      "Epoch 12/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3683 - mean_absolute_error: 0.7087\n",
      "Epoch 00012: val_loss did not improve from 0.47720\n",
      "67485/67485 [==============================] - 55s 811us/sample - loss: 0.3683 - mean_absolute_error: 0.7087 - val_loss: 0.4786 - val_mean_absolute_error: 0.8425\n",
      "Epoch 13/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3510 - mean_absolute_error: 0.6872\n",
      "Epoch 00013: val_loss improved from 0.47720 to 0.47464, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 817us/sample - loss: 0.3511 - mean_absolute_error: 0.6872 - val_loss: 0.4746 - val_mean_absolute_error: 0.8371\n",
      "Epoch 14/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3361 - mean_absolute_error: 0.6685\n",
      "Epoch 00014: val_loss improved from 0.47464 to 0.47268, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 822us/sample - loss: 0.3361 - mean_absolute_error: 0.6685 - val_loss: 0.4727 - val_mean_absolute_error: 0.8346\n",
      "Epoch 15/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3241 - mean_absolute_error: 0.6540\n",
      "Epoch 00015: val_loss did not improve from 0.47268\n",
      "67485/67485 [==============================] - 55s 815us/sample - loss: 0.3241 - mean_absolute_error: 0.6540 - val_loss: 0.4736 - val_mean_absolute_error: 0.8351\n",
      "Epoch 16/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3142 - mean_absolute_error: 0.6408\n",
      "Epoch 00016: val_loss improved from 0.47268 to 0.47181, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 819us/sample - loss: 0.3142 - mean_absolute_error: 0.6408 - val_loss: 0.4718 - val_mean_absolute_error: 0.8332\n",
      "Epoch 17/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3056 - mean_absolute_error: 0.6299\n",
      "Epoch 00017: val_loss did not improve from 0.47181\n",
      "67485/67485 [==============================] - 55s 815us/sample - loss: 0.3057 - mean_absolute_error: 0.6300 - val_loss: 0.4719 - val_mean_absolute_error: 0.8337\n",
      "Epoch 18/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2987 - mean_absolute_error: 0.6211\n",
      "Epoch 00018: val_loss improved from 0.47181 to 0.47113, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 56s 828us/sample - loss: 0.2987 - mean_absolute_error: 0.6211 - val_loss: 0.4711 - val_mean_absolute_error: 0.8324\n",
      "Epoch 19/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2934 - mean_absolute_error: 0.6141\n",
      "Epoch 00019: val_loss improved from 0.47113 to 0.46851, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 58s 865us/sample - loss: 0.2934 - mean_absolute_error: 0.6141 - val_loss: 0.4685 - val_mean_absolute_error: 0.8292\n",
      "Epoch 20/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2881 - mean_absolute_error: 0.6072\n",
      "Epoch 00020: val_loss did not improve from 0.46851\n",
      "67485/67485 [==============================] - 57s 846us/sample - loss: 0.2881 - mean_absolute_error: 0.6071 - val_loss: 0.4693 - val_mean_absolute_error: 0.8305\n",
      "Epoch 21/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2839 - mean_absolute_error: 0.6017\n",
      "Epoch 00021: val_loss did not improve from 0.46851\n",
      "67485/67485 [==============================] - 58s 865us/sample - loss: 0.2839 - mean_absolute_error: 0.6017 - val_loss: 0.4689 - val_mean_absolute_error: 0.8295\n",
      "Epoch 22/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2808 - mean_absolute_error: 0.5974\n",
      "Epoch 00022: val_loss improved from 0.46851 to 0.46670, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 59s 872us/sample - loss: 0.2808 - mean_absolute_error: 0.5973 - val_loss: 0.4667 - val_mean_absolute_error: 0.8266\n",
      "Epoch 23/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2771 - mean_absolute_error: 0.5921\n",
      "Epoch 00023: val_loss did not improve from 0.46670\n",
      "67485/67485 [==============================] - 59s 870us/sample - loss: 0.2771 - mean_absolute_error: 0.5921 - val_loss: 0.4675 - val_mean_absolute_error: 0.8275\n",
      "Epoch 24/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2745 - mean_absolute_error: 0.5889\n",
      "Epoch 00024: val_loss did not improve from 0.46670\n",
      "67485/67485 [==============================] - 59s 869us/sample - loss: 0.2745 - mean_absolute_error: 0.5889 - val_loss: 0.4678 - val_mean_absolute_error: 0.8275\n",
      "Epoch 25/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2725 - mean_absolute_error: 0.5861\n",
      "Epoch 00025: val_loss improved from 0.46670 to 0.46518, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 59s 878us/sample - loss: 0.2725 - mean_absolute_error: 0.5861 - val_loss: 0.4652 - val_mean_absolute_error: 0.8249\n",
      "Epoch 26/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2702 - mean_absolute_error: 0.5832\n",
      "Epoch 00026: val_loss improved from 0.46518 to 0.46448, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 60s 895us/sample - loss: 0.2702 - mean_absolute_error: 0.5832 - val_loss: 0.4645 - val_mean_absolute_error: 0.8243\n",
      "Epoch 27/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2683 - mean_absolute_error: 0.5809\n",
      "Epoch 00027: val_loss did not improve from 0.46448\n",
      "67485/67485 [==============================] - 58s 863us/sample - loss: 0.2683 - mean_absolute_error: 0.5809 - val_loss: 0.4649 - val_mean_absolute_error: 0.8241\n",
      "Epoch 28/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2661 - mean_absolute_error: 0.5774\n",
      "Epoch 00028: val_loss improved from 0.46448 to 0.46358, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 59s 872us/sample - loss: 0.2661 - mean_absolute_error: 0.5774 - val_loss: 0.4636 - val_mean_absolute_error: 0.8228\n",
      "Epoch 29/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2655 - mean_absolute_error: 0.5761\n",
      "Epoch 00029: val_loss improved from 0.46358 to 0.46223, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 58s 859us/sample - loss: 0.2655 - mean_absolute_error: 0.5761 - val_loss: 0.4622 - val_mean_absolute_error: 0.8211\n",
      "Epoch 30/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2624 - mean_absolute_error: 0.5720\n",
      "Epoch 00030: val_loss improved from 0.46223 to 0.46068, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 53s 783us/sample - loss: 0.2624 - mean_absolute_error: 0.5721 - val_loss: 0.4607 - val_mean_absolute_error: 0.8187\n",
      "Epoch 31/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2613 - mean_absolute_error: 0.5704\n",
      "Epoch 00031: val_loss improved from 0.46068 to 0.46037, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 53s 791us/sample - loss: 0.2613 - mean_absolute_error: 0.5705 - val_loss: 0.4604 - val_mean_absolute_error: 0.8187\n",
      "Epoch 32/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2607 - mean_absolute_error: 0.5696\n",
      "Epoch 00032: val_loss did not improve from 0.46037\n",
      "67485/67485 [==============================] - 53s 781us/sample - loss: 0.2607 - mean_absolute_error: 0.5696 - val_loss: 0.4611 - val_mean_absolute_error: 0.8194\n",
      "Epoch 33/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2597 - mean_absolute_error: 0.5683\n",
      "Epoch 00033: val_loss improved from 0.46037 to 0.45778, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 54s 805us/sample - loss: 0.2597 - mean_absolute_error: 0.5683 - val_loss: 0.4578 - val_mean_absolute_error: 0.8153\n",
      "Epoch 34/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2579 - mean_absolute_error: 0.5656\n",
      "Epoch 00034: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 54s 798us/sample - loss: 0.2579 - mean_absolute_error: 0.5656 - val_loss: 0.4594 - val_mean_absolute_error: 0.8174\n",
      "Epoch 35/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2574 - mean_absolute_error: 0.5650\n",
      "Epoch 00035: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 53s 790us/sample - loss: 0.2574 - mean_absolute_error: 0.5649 - val_loss: 0.4591 - val_mean_absolute_error: 0.8168\n",
      "Epoch 36/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2566 - mean_absolute_error: 0.5637\n",
      "Epoch 00036: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 54s 798us/sample - loss: 0.2568 - mean_absolute_error: 0.5639 - val_loss: 0.4587 - val_mean_absolute_error: 0.8163\n",
      "Epoch 37/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2563 - mean_absolute_error: 0.5632\n",
      "Epoch 00037: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 53s 784us/sample - loss: 0.2562 - mean_absolute_error: 0.5631 - val_loss: 0.4608 - val_mean_absolute_error: 0.8192\n",
      "Epoch 38/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2554 - mean_absolute_error: 0.5622\n",
      "Epoch 00038: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 53s 791us/sample - loss: 0.2554 - mean_absolute_error: 0.5622 - val_loss: 0.4617 - val_mean_absolute_error: 0.8202\n",
      "Epoch 39/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2546 - mean_absolute_error: 0.5611\n",
      "Epoch 00039: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 53s 782us/sample - loss: 0.2547 - mean_absolute_error: 0.5611 - val_loss: 0.4580 - val_mean_absolute_error: 0.8152\n",
      "Epoch 40/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2541 - mean_absolute_error: 0.5602\n",
      "Epoch 00040: val_loss did not improve from 0.45778\n",
      "67485/67485 [==============================] - 52s 777us/sample - loss: 0.2541 - mean_absolute_error: 0.5602 - val_loss: 0.4581 - val_mean_absolute_error: 0.8158\n",
      "Epoch 41/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2532 - mean_absolute_error: 0.5587\n",
      "Epoch 00041: val_loss improved from 0.45778 to 0.45662, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 53s 779us/sample - loss: 0.2532 - mean_absolute_error: 0.5587 - val_loss: 0.4566 - val_mean_absolute_error: 0.8137\n",
      "Epoch 42/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2529 - mean_absolute_error: 0.5583\n",
      "Epoch 00042: val_loss did not improve from 0.45662\n",
      "67485/67485 [==============================] - 52s 778us/sample - loss: 0.2529 - mean_absolute_error: 0.5583 - val_loss: 0.4576 - val_mean_absolute_error: 0.8152\n",
      "Epoch 43/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2523 - mean_absolute_error: 0.5577\n",
      "Epoch 00043: val_loss did not improve from 0.45662\n",
      "67485/67485 [==============================] - 53s 781us/sample - loss: 0.2523 - mean_absolute_error: 0.5577 - val_loss: 0.4574 - val_mean_absolute_error: 0.8149\n",
      "Epoch 44/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2516 - mean_absolute_error: 0.5567\n",
      "Epoch 00044: val_loss did not improve from 0.45662\n",
      "67485/67485 [==============================] - 53s 781us/sample - loss: 0.2516 - mean_absolute_error: 0.5566 - val_loss: 0.4575 - val_mean_absolute_error: 0.8148\n",
      "Epoch 45/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2510 - mean_absolute_error: 0.5557\n",
      "Epoch 00045: val_loss did not improve from 0.45662\n",
      "67485/67485 [==============================] - 55s 817us/sample - loss: 0.2510 - mean_absolute_error: 0.5557 - val_loss: 0.4568 - val_mean_absolute_error: 0.8139\n",
      "Epoch 46/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2509 - mean_absolute_error: 0.5555\n",
      "Epoch 00046: val_loss did not improve from 0.45662\n",
      "67485/67485 [==============================] - 54s 802us/sample - loss: 0.2509 - mean_absolute_error: 0.5554 - val_loss: 0.4567 - val_mean_absolute_error: 0.8138\n",
      "Epoch 47/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2504 - mean_absolute_error: 0.5546\n",
      "Epoch 00047: val_loss improved from 0.45662 to 0.45600, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 55s 810us/sample - loss: 0.2504 - mean_absolute_error: 0.5546 - val_loss: 0.4560 - val_mean_absolute_error: 0.8124\n",
      "Epoch 48/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2489 - mean_absolute_error: 0.5523\n",
      "Epoch 00048: val_loss did not improve from 0.45600\n",
      "67485/67485 [==============================] - 55s 808us/sample - loss: 0.2489 - mean_absolute_error: 0.5523 - val_loss: 0.4571 - val_mean_absolute_error: 0.8140\n",
      "Epoch 49/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2489 - mean_absolute_error: 0.5525\n",
      "Epoch 00049: val_loss improved from 0.45600 to 0.45527, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-selu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 67s 1000us/sample - loss: 0.2489 - mean_absolute_error: 0.5525 - val_loss: 0.4553 - val_mean_absolute_error: 0.8115\n",
      "Epoch 50/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2480 - mean_absolute_error: 0.5509\n",
      "Epoch 00050: val_loss did not improve from 0.45527\n",
      "67485/67485 [==============================] - 79s 1ms/sample - loss: 0.2480 - mean_absolute_error: 0.5509 - val_loss: 0.4562 - val_mean_absolute_error: 0.8126\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 1000\n",
    "# 40% dropout\n",
    "DROPOUT = 0.25\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "LAYER_ACTIVATION = \"selu\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
