{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import multiprocessing\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False,layer_activation=\"linear\"):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=layer_activation))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67485 samples, validate on 28923 samples\n",
      "Epoch 1/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.5273 - mean_absolute_error: 0.9002\n",
      "Epoch 00001: val_loss improved from inf to 0.52034, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 44s 648us/sample - loss: 0.5273 - mean_absolute_error: 0.9002 - val_loss: 0.5203 - val_mean_absolute_error: 0.8913\n",
      "Epoch 2/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5162 - mean_absolute_error: 0.8868\n",
      "Epoch 00002: val_loss improved from 0.52034 to 0.51847, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 35s 521us/sample - loss: 0.5164 - mean_absolute_error: 0.8870 - val_loss: 0.5185 - val_mean_absolute_error: 0.8892\n",
      "Epoch 3/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5106 - mean_absolute_error: 0.8800\n",
      "Epoch 00003: val_loss improved from 0.51847 to 0.51243, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 38s 559us/sample - loss: 0.5105 - mean_absolute_error: 0.8798 - val_loss: 0.5124 - val_mean_absolute_error: 0.8822\n",
      "Epoch 4/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.5037 - mean_absolute_error: 0.8718\n",
      "Epoch 00004: val_loss improved from 0.51243 to 0.50795, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 39s 578us/sample - loss: 0.5036 - mean_absolute_error: 0.8717 - val_loss: 0.5080 - val_mean_absolute_error: 0.8772\n",
      "Epoch 5/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.4957 - mean_absolute_error: 0.8624\n",
      "Epoch 00005: val_loss improved from 0.50795 to 0.50501, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 484us/sample - loss: 0.4957 - mean_absolute_error: 0.8623 - val_loss: 0.5050 - val_mean_absolute_error: 0.8734\n",
      "Epoch 6/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4841 - mean_absolute_error: 0.8484\n",
      "Epoch 00006: val_loss improved from 0.50501 to 0.49953, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 486us/sample - loss: 0.4841 - mean_absolute_error: 0.8485 - val_loss: 0.4995 - val_mean_absolute_error: 0.8665\n",
      "Epoch 7/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4708 - mean_absolute_error: 0.8324\n",
      "Epoch 00007: val_loss improved from 0.49953 to 0.49497, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 493us/sample - loss: 0.4708 - mean_absolute_error: 0.8324 - val_loss: 0.4950 - val_mean_absolute_error: 0.8615\n",
      "Epoch 8/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4532 - mean_absolute_error: 0.8113\n",
      "Epoch 00008: val_loss improved from 0.49497 to 0.49185, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 34s 506us/sample - loss: 0.4532 - mean_absolute_error: 0.8114 - val_loss: 0.4918 - val_mean_absolute_error: 0.8564\n",
      "Epoch 9/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4337 - mean_absolute_error: 0.7875\n",
      "Epoch 00009: val_loss improved from 0.49185 to 0.48649, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 34s 506us/sample - loss: 0.4337 - mean_absolute_error: 0.7874 - val_loss: 0.4865 - val_mean_absolute_error: 0.8504\n",
      "Epoch 10/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.4137 - mean_absolute_error: 0.7628\n",
      "Epoch 00010: val_loss did not improve from 0.48649\n",
      "67485/67485 [==============================] - 34s 504us/sample - loss: 0.4138 - mean_absolute_error: 0.7628 - val_loss: 0.4886 - val_mean_absolute_error: 0.8530\n",
      "Epoch 11/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3938 - mean_absolute_error: 0.7381\n",
      "Epoch 00011: val_loss improved from 0.48649 to 0.48366, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 34s 507us/sample - loss: 0.3937 - mean_absolute_error: 0.7381 - val_loss: 0.4837 - val_mean_absolute_error: 0.8470\n",
      "Epoch 12/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3766 - mean_absolute_error: 0.7170\n",
      "Epoch 00012: val_loss improved from 0.48366 to 0.48209, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 34s 510us/sample - loss: 0.3766 - mean_absolute_error: 0.7169 - val_loss: 0.4821 - val_mean_absolute_error: 0.8450\n",
      "Epoch 13/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3614 - mean_absolute_error: 0.6981\n",
      "Epoch 00013: val_loss did not improve from 0.48209\n",
      "67485/67485 [==============================] - 34s 504us/sample - loss: 0.3615 - mean_absolute_error: 0.6981 - val_loss: 0.4821 - val_mean_absolute_error: 0.8445\n",
      "Epoch 14/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3493 - mean_absolute_error: 0.6829\n",
      "Epoch 00014: val_loss did not improve from 0.48209\n",
      "67485/67485 [==============================] - 34s 509us/sample - loss: 0.3493 - mean_absolute_error: 0.6828 - val_loss: 0.4825 - val_mean_absolute_error: 0.8455\n",
      "Epoch 15/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3387 - mean_absolute_error: 0.6694\n",
      "Epoch 00015: val_loss improved from 0.48209 to 0.48081, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 35s 511us/sample - loss: 0.3387 - mean_absolute_error: 0.6694 - val_loss: 0.4808 - val_mean_absolute_error: 0.8430\n",
      "Epoch 16/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3303 - mean_absolute_error: 0.6587\n",
      "Epoch 00016: val_loss improved from 0.48081 to 0.47997, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 35s 513us/sample - loss: 0.3302 - mean_absolute_error: 0.6587 - val_loss: 0.4800 - val_mean_absolute_error: 0.8420\n",
      "Epoch 17/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3242 - mean_absolute_error: 0.6506\n",
      "Epoch 00017: val_loss did not improve from 0.47997\n",
      "67485/67485 [==============================] - 36s 528us/sample - loss: 0.3242 - mean_absolute_error: 0.6506 - val_loss: 0.4820 - val_mean_absolute_error: 0.8441\n",
      "Epoch 18/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3181 - mean_absolute_error: 0.6428\n",
      "Epoch 00018: val_loss improved from 0.47997 to 0.47930, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 35s 511us/sample - loss: 0.3182 - mean_absolute_error: 0.6428 - val_loss: 0.4793 - val_mean_absolute_error: 0.8405\n",
      "Epoch 19/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3132 - mean_absolute_error: 0.6362\n",
      "Epoch 00019: val_loss improved from 0.47930 to 0.47535, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 34s 500us/sample - loss: 0.3133 - mean_absolute_error: 0.6363 - val_loss: 0.4754 - val_mean_absolute_error: 0.8362\n",
      "Epoch 20/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3090 - mean_absolute_error: 0.6305\n",
      "Epoch 00020: val_loss did not improve from 0.47535\n",
      "67485/67485 [==============================] - 32s 481us/sample - loss: 0.3090 - mean_absolute_error: 0.6306 - val_loss: 0.4767 - val_mean_absolute_error: 0.8379\n",
      "Epoch 21/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.3061 - mean_absolute_error: 0.6266\n",
      "Epoch 00021: val_loss improved from 0.47535 to 0.47495, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 486us/sample - loss: 0.3061 - mean_absolute_error: 0.6266 - val_loss: 0.4750 - val_mean_absolute_error: 0.8353\n",
      "Epoch 22/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.3029 - mean_absolute_error: 0.6223\n",
      "Epoch 00022: val_loss did not improve from 0.47495\n",
      "67485/67485 [==============================] - 33s 488us/sample - loss: 0.3030 - mean_absolute_error: 0.6223 - val_loss: 0.4761 - val_mean_absolute_error: 0.8372\n",
      "Epoch 23/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2999 - mean_absolute_error: 0.6183\n",
      "Epoch 00023: val_loss did not improve from 0.47495\n",
      "67485/67485 [==============================] - 33s 488us/sample - loss: 0.2998 - mean_absolute_error: 0.6183 - val_loss: 0.4756 - val_mean_absolute_error: 0.8362\n",
      "Epoch 24/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2980 - mean_absolute_error: 0.6152\n",
      "Epoch 00024: val_loss improved from 0.47495 to 0.47417, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 491us/sample - loss: 0.2979 - mean_absolute_error: 0.6151 - val_loss: 0.4742 - val_mean_absolute_error: 0.8341\n",
      "Epoch 25/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2958 - mean_absolute_error: 0.6123\n",
      "Epoch 00025: val_loss improved from 0.47417 to 0.47359, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 489us/sample - loss: 0.2958 - mean_absolute_error: 0.6122 - val_loss: 0.4736 - val_mean_absolute_error: 0.8339\n",
      "Epoch 26/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2939 - mean_absolute_error: 0.6098\n",
      "Epoch 00026: val_loss did not improve from 0.47359\n",
      "67485/67485 [==============================] - 33s 486us/sample - loss: 0.2939 - mean_absolute_error: 0.6098 - val_loss: 0.4742 - val_mean_absolute_error: 0.8344\n",
      "Epoch 27/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2919 - mean_absolute_error: 0.6070\n",
      "Epoch 00027: val_loss improved from 0.47359 to 0.47041, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 491us/sample - loss: 0.2919 - mean_absolute_error: 0.6071 - val_loss: 0.4704 - val_mean_absolute_error: 0.8298\n",
      "Epoch 28/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2907 - mean_absolute_error: 0.6058\n",
      "Epoch 00028: val_loss did not improve from 0.47041\n",
      "67485/67485 [==============================] - 33s 486us/sample - loss: 0.2907 - mean_absolute_error: 0.6059 - val_loss: 0.4720 - val_mean_absolute_error: 0.8315\n",
      "Epoch 29/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2896 - mean_absolute_error: 0.6040\n",
      "Epoch 00029: val_loss did not improve from 0.47041\n",
      "67485/67485 [==============================] - 33s 487us/sample - loss: 0.2896 - mean_absolute_error: 0.6040 - val_loss: 0.4719 - val_mean_absolute_error: 0.8315\n",
      "Epoch 30/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2887 - mean_absolute_error: 0.6029\n",
      "Epoch 00030: val_loss did not improve from 0.47041\n",
      "67485/67485 [==============================] - 33s 488us/sample - loss: 0.2887 - mean_absolute_error: 0.6029 - val_loss: 0.4728 - val_mean_absolute_error: 0.8325\n",
      "Epoch 31/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2867 - mean_absolute_error: 0.5999\n",
      "Epoch 00031: val_loss did not improve from 0.47041\n",
      "67485/67485 [==============================] - 33s 487us/sample - loss: 0.2873 - mean_absolute_error: 0.6004 - val_loss: 0.4708 - val_mean_absolute_error: 0.8297\n",
      "Epoch 32/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2858 - mean_absolute_error: 0.5982\n",
      "Epoch 00032: val_loss improved from 0.47041 to 0.47029, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 492us/sample - loss: 0.2857 - mean_absolute_error: 0.5982 - val_loss: 0.4703 - val_mean_absolute_error: 0.8286\n",
      "Epoch 33/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2851 - mean_absolute_error: 0.5975\n",
      "Epoch 00033: val_loss improved from 0.47029 to 0.46849, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 490us/sample - loss: 0.2851 - mean_absolute_error: 0.5975 - val_loss: 0.4685 - val_mean_absolute_error: 0.8269\n",
      "Epoch 34/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2850 - mean_absolute_error: 0.5972\n",
      "Epoch 00034: val_loss did not improve from 0.46849\n",
      "67485/67485 [==============================] - 33s 490us/sample - loss: 0.2851 - mean_absolute_error: 0.5972 - val_loss: 0.4700 - val_mean_absolute_error: 0.8287\n",
      "Epoch 35/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2835 - mean_absolute_error: 0.5952\n",
      "Epoch 00035: val_loss improved from 0.46849 to 0.46837, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 488us/sample - loss: 0.2835 - mean_absolute_error: 0.5952 - val_loss: 0.4684 - val_mean_absolute_error: 0.8271\n",
      "Epoch 36/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2824 - mean_absolute_error: 0.5936\n",
      "Epoch 00036: val_loss did not improve from 0.46837\n",
      "67485/67485 [==============================] - 33s 491us/sample - loss: 0.2824 - mean_absolute_error: 0.5936 - val_loss: 0.4684 - val_mean_absolute_error: 0.8263\n",
      "Epoch 37/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2822 - mean_absolute_error: 0.5934\n",
      "Epoch 00037: val_loss improved from 0.46837 to 0.46598, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 494us/sample - loss: 0.2821 - mean_absolute_error: 0.5934 - val_loss: 0.4660 - val_mean_absolute_error: 0.8237\n",
      "Epoch 38/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2816 - mean_absolute_error: 0.5924\n",
      "Epoch 00038: val_loss did not improve from 0.46598\n",
      "67485/67485 [==============================] - 33s 485us/sample - loss: 0.2815 - mean_absolute_error: 0.5923 - val_loss: 0.4689 - val_mean_absolute_error: 0.8273\n",
      "Epoch 39/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2799 - mean_absolute_error: 0.5904\n",
      "Epoch 00039: val_loss did not improve from 0.46598\n",
      "67485/67485 [==============================] - 33s 485us/sample - loss: 0.2807 - mean_absolute_error: 0.5911 - val_loss: 0.4678 - val_mean_absolute_error: 0.8260\n",
      "Epoch 40/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2801 - mean_absolute_error: 0.5902\n",
      "Epoch 00040: val_loss did not improve from 0.46598\n",
      "67485/67485 [==============================] - 33s 482us/sample - loss: 0.2801 - mean_absolute_error: 0.5902 - val_loss: 0.4676 - val_mean_absolute_error: 0.8260\n",
      "Epoch 41/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2792 - mean_absolute_error: 0.5888\n",
      "Epoch 00041: val_loss improved from 0.46598 to 0.46526, saving model to results\\2021-12-01_MIXED-huber_loss-adam-LSTM-elu-layers-3-units-1000-b.h5\n",
      "67485/67485 [==============================] - 33s 491us/sample - loss: 0.2791 - mean_absolute_error: 0.5888 - val_loss: 0.4653 - val_mean_absolute_error: 0.8229\n",
      "Epoch 42/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2795 - mean_absolute_error: 0.5893\n",
      "Epoch 00042: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 33s 484us/sample - loss: 0.2795 - mean_absolute_error: 0.5893 - val_loss: 0.4670 - val_mean_absolute_error: 0.8248\n",
      "Epoch 43/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2784 - mean_absolute_error: 0.5875\n",
      "Epoch 00043: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 33s 487us/sample - loss: 0.2784 - mean_absolute_error: 0.5876 - val_loss: 0.4661 - val_mean_absolute_error: 0.8235\n",
      "Epoch 44/50\n",
      "67456/67485 [============================>.] - ETA: 0s - loss: 0.2782 - mean_absolute_error: 0.5876\n",
      "Epoch 00044: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 34s 505us/sample - loss: 0.2782 - mean_absolute_error: 0.5876 - val_loss: 0.4664 - val_mean_absolute_error: 0.8235\n",
      "Epoch 45/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2772 - mean_absolute_error: 0.5859\n",
      "Epoch 00045: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 34s 504us/sample - loss: 0.2773 - mean_absolute_error: 0.5860 - val_loss: 0.4680 - val_mean_absolute_error: 0.8256\n",
      "Epoch 46/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2773 - mean_absolute_error: 0.5858\n",
      "Epoch 00046: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 34s 503us/sample - loss: 0.2772 - mean_absolute_error: 0.5857 - val_loss: 0.4676 - val_mean_absolute_error: 0.8253\n",
      "Epoch 47/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2767 - mean_absolute_error: 0.5848\n",
      "Epoch 00047: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 34s 503us/sample - loss: 0.2766 - mean_absolute_error: 0.5847 - val_loss: 0.4659 - val_mean_absolute_error: 0.8229\n",
      "Epoch 48/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2762 - mean_absolute_error: 0.5842\n",
      "Epoch 00048: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 34s 503us/sample - loss: 0.2761 - mean_absolute_error: 0.5841 - val_loss: 0.4656 - val_mean_absolute_error: 0.8230\n",
      "Epoch 49/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2757 - mean_absolute_error: 0.5840\n",
      "Epoch 00049: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 35s 518us/sample - loss: 0.2763 - mean_absolute_error: 0.5845 - val_loss: 0.4673 - val_mean_absolute_error: 0.8249\n",
      "Epoch 50/50\n",
      "67392/67485 [============================>.] - ETA: 0s - loss: 0.2755 - mean_absolute_error: 0.5833\n",
      "Epoch 00050: val_loss did not improve from 0.46526\n",
      "67485/67485 [==============================] - 35s 516us/sample - loss: 0.2756 - mean_absolute_error: 0.5834 - val_loss: 0.4664 - val_mean_absolute_error: 0.8241\n"
     ]
    }
   ],
   "source": [
    "#def run_tensorflow():\n",
    "\n",
    "# create these folders if they does not exist\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 72\n",
    "# Lookup step, 1 is the next day\n",
    "#LOOKUP_STEP = int(run_dict[run][\"LOOKUP_STEP\"])\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.3\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"close_0\",\"ema_0\",\"high_0\",\"low_0\",\"open_0\",\"rsi_0\",\"sma_0\",\"volume_0\",\"close_1\",\"ema_1\",\"high_1\",\"low_1\",\"open_1\",\"rsi_1\",\"sma_1\",\"volume_1\",\n",
    "                   \"close_2\",\"ema_2\",\"high_2\",\"low_2\",\"open_2\",\"rsi_2\",\"sma_2\",\"volume_2\",\"close_3\",\"ema_3\",\"high_3\",\"low_3\",\"open_3\",\"rsi_3\",\"sma_3\",\"volume_3\",\n",
    "                   \"close_4\",\"ema_4\",\"high_4\",\"low_4\",\"open_4\",\"rsi_4\",\"sma_4\",\"volume_4\",\"close_5\",\"ema_5\",\"high_5\",\"low_5\",\"open_5\",\"rsi_5\",\"sma_5\",\"volume_5\",\n",
    "                   \"close_6\",\"ema_6\",\"high_6\",\"low_6\",\"open_6\",\"rsi_6\",\"sma_6\",\"volume_6\",\"close_7\",\"ema_7\",\"high_7\",\"low_7\",\"open_7\",\"rsi_7\",\"sma_7\",\"volume_7\",\n",
    "                   \"close_8\",\"ema_8\",\"high_8\",\"low_8\",\"open_8\",\"rsi_8\",\"sma_8\",\"volume_8\"]\n",
    "TARGET_COLUMNS = [\"close_9\",\"high_9\",\"low_9\",\"open_9\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 3\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 1000\n",
    "# 40% dropout\n",
    "DROPOUT = 0.25\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "LAYER_ACTIVATION = \"elu\"\n",
    "\n",
    "# Stock market\n",
    "ticker = \"MIXED\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-{LAYER_ACTIVATION}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#try:\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('../data/processed/all_processed_10.csv')\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL, layer_activation=LAYER_ACTIVATION)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "X = data[FEATURE_COLUMNS]\n",
    "y = data[TARGET_COLUMNS]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape X to fit the neural network\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "\n",
    "#except:\n",
    "#    print(\"There was an attempt.\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
